{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "- train: 학습용\n",
    "- val: 검증용\n",
    "> 기존 데이터 셋, 8:2 split (train, val)\n",
    "\n",
    "- test: 최종 테스트용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import (\n",
    "CategoryEmbeddingModelConfig,\n",
    "FTTransformerConfig,\n",
    "TabNetModelConfig,\n",
    "GANDALFConfig,\n",
    ")\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.stacking import StackingModelConfig\n",
    "# from pytorch_tabular.utils import make_mixed_dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer, QuantileTransformer, MultiLabelBinarizer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import random\n",
    "\n",
    "import preprocessing\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "source": [
    "data_seed = 1\n",
    "seed = 333\n",
    "\n",
    "train_path = f'../../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "source": [
    "train, test = preprocessing.all_process(train, test)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 57개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config\n",
    "- continuous_cols 기본 설정 뺴기 @@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기본 학습 관련 config\n",
    "data_config = DataConfig(\n",
    "    target=[\"임신 성공 여부\"],\n",
    "    continuous_cols=numeric_cols,\n",
    "    categorical_cols=cat_cols,\n",
    "    normalize_continuous_features=False,     # 정규화 기본 설정 False로 수정\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=4096,\n",
    "    max_epochs=20,\n",
    "    early_stopping=\"valid_loss\",     \n",
    "    early_stopping_mode=\"min\",\n",
    "    early_stopping_patience=3,\n",
    "    checkpoints=\"valid_loss\",        \n",
    "    load_best=True, \n",
    "    auto_lr_find=False,\n",
    ")\n",
    "optimizer_config = OptimizerConfig()  # default: Adam, 1e-3\n",
    "\n",
    "## stacking 할 모델들 config\n",
    "model_config_1 = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"128-64-32\",\n",
    "    activation=\"ReLU\",\n",
    "    learning_rate=1e-3,\n",
    "    seed=seed\n",
    ")\n",
    "model_config_2 = FTTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    input_embed_dim=32,\n",
    "    num_attn_blocks=2,\n",
    "    num_heads=4,\n",
    "    learning_rate=1e-3,\n",
    "    seed=seed\n",
    ")\n",
    "model_config_3 = TabNetModelConfig(\n",
    "    task=\"classification\",\n",
    "    n_d=16,\n",
    "    n_a=16,\n",
    "    n_steps=5,\n",
    "    learning_rate=1e-3,\n",
    "    seed=seed\n",
    ")\n",
    "model_config_4 = GANDALFConfig(\n",
    "    task=\"classification\",\n",
    "    gflu_stages=6,\n",
    "    gflu_dropout=0.1,\n",
    "    gflu_feature_init_sparsity=0.3,  # 각 GFLU 스테이지에서 처음에 선택할 feature의 비율\n",
    "    learnable_sparsity=True,  # GFLU에서 선택할 feature의 sparsity 비율을 학습 중에 업데이트할지 여부\n",
    "    embedding_dropout=0.05,\n",
    "    batch_norm_continuous_input=False,  # 연속형 정규화 안함\n",
    "    learning_rate=1e-3,\n",
    "    seed=seed,    \n",
    ")\n",
    "\n",
    "## stacking model config\n",
    "stacking_config = StackingModelConfig(\n",
    "    task=\"classification\",\n",
    "    model_configs=[\n",
    "        model_config_1,\n",
    "        model_config_2,\n",
    "        model_config_3,\n",
    "        model_config_4\n",
    "    ],\n",
    "    head=\"LinearHead\",\n",
    "    head_config={\n",
    "        \"layers\": \"64\",\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"dropout\": 0.1\n",
    "    },\n",
    "    learning_rate=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftVoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:59:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">395</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">549</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m04:59:38\u001b[0m,\u001b[1;36m395\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m549\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:59:38</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">611</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:527</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m04:59:38\u001b[0m,\u001b[1;36m611\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:527\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:59:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">197</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: StackingModel          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m04:59:39\u001b[0m,\u001b[1;36m197\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m600\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: StackingModel          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:59:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">670</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">343</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m04:59:39\u001b[0m,\u001b[1;36m670\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m343\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:59:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">780</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">679</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m04\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m04:59:39\u001b[0m,\u001b[1;36m780\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m679\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe MIG 1g.10gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ StackingBackbone       │  378 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ StackingEmbeddingLayer │  6.2 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ LinearHead             │ 17.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss       │      0 │ train │\n",
       "└───┴──────────────────┴────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ StackingBackbone       │  378 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ StackingEmbeddingLayer │  6.2 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ LinearHead             │ 17.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss       │      0 │ train │\n",
       "└───┴──────────────────┴────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 402 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 402 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 284                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 402 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 402 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 284                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc285760128444a90ff767db24f98bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC AUC\n",
    "def _roc_auc_scoer(y_true, y_pred):\n",
    "    return roc_auc_score(y_true, y_pred['임신 성공 여부_1_probability'])\n",
    "\n",
    "# 모델 설정 리스트 (각 모델의 config)\n",
    "model_configs = [model_config_1, model_config_2, model_config_3, model_config_4]\n",
    "\n",
    "# 각 모델의 예측 확률을 저장할 리스트와 개별 AUC 기록 리스트\n",
    "predictions = []\n",
    "individual_auc = []\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "seed = 333\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "for i, config in enumerate(model_configs):\n",
    "    # 각 모델 독립적으로 초기화\n",
    "    main_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config\n",
    "    )\n",
    "    \n",
    "    # 각 모델 폴드별 roc 확인용\n",
    "    roc_metrics = []\n",
    "    \n",
    "    # StratifiedKFold\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "        \n",
    "        # 현재 fold의 train/validation 데이터 분할\n",
    "        train_fold = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        val_fold = train.iloc[val_idx].copy().reset_index(drop=True)    \n",
    "        \n",
    "        train2_fold = train_fold.copy()\n",
    "        test_fold = test.copy() \n",
    "        \n",
    "        # preprocessing\n",
    "        train_fold, val_fold = preprocessing.all_process(train_fold, val_fold)\n",
    "        train2_fold, test_fold = preprocessing.all_process(train2_fold, test_fold)\n",
    "        \n",
    "        # 첫 fold일 때 datamodule과 모델 초기화, 이후 fold에서는 copy로 재사용\n",
    "        if fold == 0:\n",
    "            datamodule = main_model.prepare_dataloader(train=train_fold, validation=val_fold, seed=seed)\n",
    "            model = main_model.prepare_model(datamodule)\n",
    "        else:\n",
    "            datamodule = datamodule.copy(train=train_fold, validation=val_fold)\n",
    "        \n",
    "        # Train\n",
    "        main_model.train(model, datamodule)\n",
    "        \n",
    "        # Val\n",
    "        pred_df = main_model.predict(val_fold)\n",
    "        \n",
    "        # Test\n",
    "        pred_test = main_model.predict(test_fold)\n",
    "        test_preds.append(pred_test)\n",
    "        \n",
    "        # Evaluation\n",
    "        fold_roc = _roc_auc_scoer(val_fold['임신 성공 여부'], pred_df)\n",
    "        roc_metrics.append(fold_roc)\n",
    "\n",
    "        print(f'Fold{fold+1} | ROC AUC:{fold_roc:.8f}')\n",
    "        \n",
    "        # 모델 가중치 초기화\n",
    "        main_model.model.reset_weights()\n",
    "    \n",
    "    # 5개 폴드 평가지표(AUC) 평균\n",
    "    average_roc_auc = np.mean(roc_metrics, axis=0)\n",
    "    print(f'model: {config} | Average AUC: {average_roc_auc:.8f}')\n",
    "        \n",
    "    \n",
    "    \n",
    "    # 모델 학습 (train 데이터 사용)\n",
    "    model.train(train)\n",
    "    \n",
    "    # 검증 데이터에 대해 예측 수행\n",
    "    pred_df = model.predict(val)\n",
    "    # \"임신 성공 여부_1_probability\" 컬럼에 예측 확률이 있다고 가정\n",
    "    prob = pred_df[\"임신 성공 여부_1_probability\"].values\n",
    "    \n",
    "    # 각 모델의 예측 확률 저장\n",
    "    predictions.append(prob)\n",
    "    \n",
    "    # ROC AUC 계산 및 출력\n",
    "    auc = roc_auc_score(val[\"임신 성공 여부\"], prob)\n",
    "    individual_auc.append(auc)\n",
    "    print(f\"Model {i+1} ROC AUC: {auc:.4f}\")\n",
    "\n",
    "# 예측 확률 배열로 변환 (shape: [n_models, n_samples])\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Soft Voting: 각 모델의 예측 확률 평균 계산\n",
    "avg_pred = np.mean(predictions, axis=0)\n",
    "\n",
    "# 앙상블 모델의 ROC AUC 계산 및 출력\n",
    "ensemble_auc = roc_auc_score(val[\"임신 성공 여부\"], avg_pred)\n",
    "print(f\"Soft Voting Ensemble ROC AUC: {ensemble_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_submission = pd.DataFrame({f'stacking_{data_seed}': final_test_preds})\n",
    "tmp_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "\n",
    "score = calculate_auc(tmp_submission, seed=data_seed)\n",
    "print(f'[Seed: {data_seed}]: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
