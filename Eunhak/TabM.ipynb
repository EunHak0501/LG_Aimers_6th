{
 "cells": [
  {
   "cell_type": "code",
   "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:17.776391Z",
     "start_time": "2025-03-30T02:11:15.053384Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import shutil\n",
    "import ipynbname\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer, QuantileTransformer, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import rtdl_num_embeddings\n",
    "\n",
    "from Process_Function import RareCategoryTransformer\n",
    "from Visualization_function import *\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:18.661915Z",
     "start_time": "2025-03-30T02:11:17.787393Z"
    }
   },
   "source": [
    "data_seed = 10\n",
    "\n",
    "train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:22.933599Z",
     "start_time": "2025-03-30T02:11:18.709914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def drop_columns(df):\n",
    "    cols = [\n",
    "        '불임 원인 - 여성 요인',  # 고유값 1\n",
    "        '불임 원인 - 정자 면역학적 요인',  # train, test 모두 '1'인 데이터 1개 >> 신뢰할 수 없음\n",
    "        '난자 해동 경과일',\n",
    "    ]\n",
    "    df = df.drop(cols, axis=1)\n",
    "    return df\n",
    "\n",
    "def 특정시술유형(train, test):\n",
    "    def categorize_procedure(proc):\n",
    "        tokens = [token.strip() for token in proc.split(\",\") if token.strip() and not token.strip().isdigit()]\n",
    "        # 우선순위에 따른 범주화\n",
    "        if tokens.count(\"Unknown\") >= 1:\n",
    "            return \"Unknown\"\n",
    "        if tokens.count(\"AH\") >= 1:\n",
    "            return \"AH\"\n",
    "        if tokens.count(\"BLASTOCYST\") >= 1:\n",
    "            return \"BLASTOCYST\"\n",
    "        if tokens.count(\"ICSI\") >= 2 or tokens.count(\"IVF\") >= 2:\n",
    "            return \"2ICSI_2IVF\"\n",
    "        if tokens.count(\"IVF\") >= 1 and tokens.count(\"ICSI\") >= 1:\n",
    "            return \"IVF_ICSI\"\n",
    "        if tokens == \"ICSI\":\n",
    "            return \"ICSI\"\n",
    "        if tokens == \"IVF\":\n",
    "            return \"IVF\"\n",
    "        return \",\".join(tokens) if tokens else None\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\" / \", \",\")\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\":\", \",\")\n",
    "        df['특정 시술 유형'] = df['특정 시술 유형'].str.replace(\" \", \"\")\n",
    "\n",
    "    counts = train['특정 시술 유형'].value_counts()\n",
    "    allowed_categories = counts[counts >= 100].index.tolist()\n",
    "\n",
    "    # allowed_categories에 속하지 않는 값은 \"Unknown\"으로 대체\n",
    "    train.loc[~train['특정 시술 유형'].isin(allowed_categories), '특정 시술 유형'] = \"Unknown\"\n",
    "    test.loc[~test['특정 시술 유형'].isin(allowed_categories), '특정 시술 유형'] = \"Unknown\"\n",
    "\n",
    "    train['특정 시술 유형'] = train['특정 시술 유형'].apply(categorize_procedure)\n",
    "    test['특정 시술 유형'] = test['특정 시술 유형'].apply(categorize_procedure)\n",
    "\n",
    "    train['시술유형_통합'] = train['시술 유형'].astype(str) + '_' + train['특정 시술 유형'].astype(str)\n",
    "    test['시술유형_통합'] = test['시술 유형'].astype(str) + '_' + test['특정 시술 유형'].astype(str)\n",
    "\n",
    "    drop_cols = ['시술 유형', '특정 시술 유형']\n",
    "    train = train.drop(drop_cols, axis=1)\n",
    "    test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def 시술횟수(df_train):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상':'6회'})\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "    df_train['시술_임신'] = df_train['총 임신 횟수'] - df_train['총 시술 횟수']\n",
    "    df_train = df_train.drop('총 시술 횟수', axis=1)\n",
    "    return df_train\n",
    "\n",
    "def 배란유도유형(df_train, df_test):\n",
    "    mapping = {\n",
    "        '기록되지 않은 시행': 1,\n",
    "        '알 수 없음': 0,\n",
    "        '세트로타이드 (억제제)': 0,\n",
    "        '생식선 자극 호르몬': 0,\n",
    "    }\n",
    "    df_train['배란 유도 유형'] = df_train['배란 유도 유형'].replace(mapping)\n",
    "    df_test['배란 유도 유형'] = df_test['배란 유도 유형'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def 난자기증자나이(df_train, df_test):\n",
    "    mapping = {\n",
    "        '만20세 이하': 20,\n",
    "        '만21-25세': 25,\n",
    "        '만26-30세': 30,\n",
    "        '만31-35세': 35,\n",
    "        '알 수 없음': 20,  # 만20세 이하와 동일하게 처리\n",
    "    }\n",
    "    df_train['난자 기증자 나이'] = df_train['난자 기증자 나이'].replace(mapping)\n",
    "    df_test['난자 기증자 나이'] = df_test['난자 기증자 나이'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def 배아생성주요이유(df_train, df_test):\n",
    "    df_train['배아 생성 주요 이유'] = df_train['배아 생성 주요 이유'].fillna('DI')\n",
    "    df_test['배아 생성 주요 이유'] = df_test['배아 생성 주요 이유'].fillna('DI')\n",
    "\n",
    "    df_train['배아 생성 이유 리스트'] = df_train['배아 생성 주요 이유'].apply(lambda x: [reason.strip() for reason in x.split(',')])\n",
    "    df_test['배아 생성 이유 리스트'] = df_test['배아 생성 주요 이유'].apply(lambda x: [reason.strip() for reason in x.split(',')])\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    train_one_hot = pd.DataFrame(\n",
    "        mlb.fit_transform(df_train['배아 생성 이유 리스트']),\n",
    "        columns=mlb.classes_,\n",
    "        index=df_train.index\n",
    "    )\n",
    "    train_one_hot.columns = ['배아생성이유_' + col for col in train_one_hot.columns]\n",
    "\n",
    "    test_one_hot = pd.DataFrame(\n",
    "        mlb.transform(df_test['배아 생성 이유 리스트']),\n",
    "        columns=mlb.classes_,\n",
    "        index=df_test.index\n",
    "    )\n",
    "    test_one_hot.columns = ['배아생성이유_' + col for col in test_one_hot.columns]\n",
    "\n",
    "    df_train = pd.concat([df_train, train_one_hot], axis=1)\n",
    "    df_test = pd.concat([df_test, test_one_hot], axis=1)\n",
    "\n",
    "    cols_to_drop = [\n",
    "        '배아 생성 주요 이유',\n",
    "        '배아 생성 이유 리스트',\n",
    "        '배아생성이유_연구용',\n",
    "        '배아생성이유_DI'\n",
    "    ]\n",
    "    df_train = df_train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "    df_test = df_test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "    cols = ['배아생성이유_기증용',\n",
    "            '배아생성이유_난자 저장용',\n",
    "            '배아생성이유_배아 저장용',\n",
    "            '배아생성이유_현재 시술용']\n",
    "\n",
    "    df_train[cols] = df_train[cols].div(df_train[cols].sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "    df_test[cols] = df_test[cols].div(df_test[cols].sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "def 단일배아이식여부(df_train, df_val):\n",
    "    df_train['단일 배아 이식 여부'] = df_train['단일 배아 이식 여부'].fillna(0)\n",
    "    df_val['단일 배아 이식 여부'] = df_val['단일 배아 이식 여부'].fillna(0)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def 기증자정자와혼합된난자수(df_train, df_test):\n",
    "    df_train[\"기증자 정자와 혼합된 난자 수\"] = df_train[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    df_test[\"기증자 정자와 혼합된 난자 수\"] = df_test[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    return df_train, df_test\n",
    "\n",
    "def label_encoding(train, test, cols):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cols:\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        test[col] = encoder.transform(test[col])\n",
    "    return train, test\n",
    "\n",
    "def type_to_category(train, test, cols):\n",
    "    train[cols] = train[cols].astype('category')\n",
    "    test[cols] = test[cols].astype('category')\n",
    "    return train, test\n",
    "\n",
    "def impute_nan(train, test):\n",
    "    cols_to_impute = [\n",
    "        '임신 시도 또는 마지막 임신 경과 연수', # DI, IVF랑 관련 X\n",
    "    ]\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    train[cols_to_impute] = imputer.fit_transform(train[cols_to_impute])\n",
    "    test[cols_to_impute] = imputer.transform(test[cols_to_impute])\n",
    "\n",
    "    cols_to_impute = [\n",
    "        '난자 채취 경과일',\n",
    "        '난자 혼합 경과일',\n",
    "        '배아 이식 경과일',\n",
    "        '배아 해동 경과일',\n",
    "\n",
    "        '착상 전 유전 검사 사용 여부',\n",
    "        'PGD 시술 여부',\n",
    "        'PGS 시술 여부',\n",
    "\n",
    "        ### DI only\n",
    "        '착상 전 유전 진단 사용 여부',\n",
    "        '총 생성 배아 수',\n",
    "        '미세주입된 난자 수',\n",
    "        '미세주입에서 생성된 배아 수',\n",
    "        '이식된 배아 수',\n",
    "        '미세주입 배아 이식 수',\n",
    "        '저장된 배아 수',\n",
    "        '미세주입 후 저장된 배아 수',\n",
    "        '해동된 배아 수',\n",
    "        '해동 난자 수',\n",
    "        '수집된 신선 난자 수',\n",
    "        '저장된 신선 난자 수',\n",
    "        '혼합된 난자 수',\n",
    "        '파트너 정자와 혼합된 난자 수',\n",
    "        '기증자 정자와 혼합된 난자 수',\n",
    "        '동결 배아 사용 여부',\n",
    "        '신선 배아 사용 여부',\n",
    "        '기증 배아 사용 여부',\n",
    "        '대리모 여부',\n",
    "        ### DI\n",
    "    ]\n",
    "    train[cols_to_impute] = train[cols_to_impute].fillna(0)\n",
    "    test[cols_to_impute] = test[cols_to_impute].fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def num_feature_scailing(train, test, seed=777):\n",
    "    numeric_cols = train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "    cols_to_scale = [\n",
    "        col for col in numeric_cols\n",
    "        if col not in cat_cols and col != '임신 성공 여부'\n",
    "    ]\n",
    "\n",
    "    arr_train = train[cols_to_scale].to_numpy()  # DataFrame -> NumPy\n",
    "    arr_train = arr_train.astype(np.float32)\n",
    "    arr_test = test[cols_to_scale].to_numpy()\n",
    "    arr_test = arr_test.astype(np.float32)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    noise = (\n",
    "        np.random.default_rng(0)\n",
    "        .normal(0.0, 1e-5, arr_train.shape)\n",
    "        .astype(arr_train.dtype)\n",
    "    )\n",
    "    preprocessing = QuantileTransformer(\n",
    "        n_quantiles=max(min(len(train[cols_to_scale]) // 30, 1000), 10),\n",
    "        output_distribution='normal',\n",
    "        subsample=10**9,\n",
    "    ).fit(arr_train + noise)\n",
    "\n",
    "    # train[cols_to_scale] = preprocessing.transform(arr_train + noise)\n",
    "    train[cols_to_scale] = preprocessing.transform(arr_train)\n",
    "    test[cols_to_scale] = preprocessing.transform(arr_test)\n",
    "    return train, test\n",
    "\n",
    "def drop_single_value_columns(df_train, df_test):\n",
    "    cols_to_drop = [col for col in df_train.columns if df_train[col].nunique() == 1]\n",
    "    return df_train.drop(columns=cols_to_drop), df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "def all_process(train, val):\n",
    "    # 기본 전처리 단계\n",
    "    train, val = drop_columns(train), drop_columns(val)\n",
    "    train, val = 특정시술유형(train, val)\n",
    "    train, val = 시술횟수(train), 시술횟수(val)\n",
    "\n",
    "    train, val = 단일배아이식여부(train, val)\n",
    "    train, val = 배란유도유형(train, val)\n",
    "    train, val = 배아생성주요이유(train, val)\n",
    "\n",
    "    cols_to_encoding = [\n",
    "        \"시술 시기 코드\",\n",
    "        \"시술 당시 나이\",\n",
    "        \"배란 유도 유형\",\n",
    "        # \"클리닉 내 총 시술 횟수\",\n",
    "        # \"IVF 시술 횟수\",\n",
    "        # \"DI 시술 횟수\",\n",
    "        # \"총 임신 횟수\",\n",
    "        # \"IVF 임신 횟수\",\n",
    "        # \"DI 임신 횟수\",\n",
    "        # \"총 출산 횟수\",\n",
    "        # \"IVF 출산 횟수\",\n",
    "        # \"DI 출산 횟수\",\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "        '시술유형_통합',\n",
    "    ]\n",
    "    train, val = label_encoding(train, val, cols=cols_to_encoding)\n",
    "    train, val = type_to_category(train, val, cols=cols_to_encoding)\n",
    "\n",
    "    train, val = impute_nan(train, val)\n",
    "    train, val = num_feature_scailing(train, val)\n",
    "\n",
    "    train, val = drop_single_value_columns(train, val)\n",
    "\n",
    "    return train, val\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ],
   "id": "63299de32ba2bec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 57개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:23.147597Z",
     "start_time": "2025-03-30T02:11:22.965598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feature_info(train, target_col='임신 성공 여부'):\n",
    "    n_num_features_ = len(numeric_cols)\n",
    "    cat_cardinalities_ = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return n_num_features_, cat_cardinalities_\n",
    "\n",
    "def to_dataloader(df, batch_size=256, is_shuffle=True, is_train=True, target_col='임신 성공 여부'):\n",
    "    X_num = torch.tensor(df[numeric_cols].values, dtype=torch.float32)\n",
    "    X_cat = torch.tensor(df[cat_cols].values, dtype=torch.long)\n",
    "\n",
    "    if is_train:\n",
    "        y = torch.tensor(df[target_col].values, dtype=torch.float32)\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat, y)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "    else:\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "n_num_features, cat_cardinalities = get_feature_info(train)\n",
    "print(n_num_features)\n",
    "print(cat_cardinalities)\n",
    "\n",
    "train_loader = to_dataloader(train)\n",
    "test_loader = to_dataloader(test, is_shuffle=False, is_train=False)"
   ],
   "id": "7175bdaadb738a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "[7, 7, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:23.178598Z",
     "start_time": "2025-03-30T02:11:23.164597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabMWrapper:\n",
    "    def __init__(self, model_config, trainer_config):\n",
    "        self.device = trainer_config.get(\"device\") or torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        self.lr = trainer_config.get(\"lr\", 0.001)\n",
    "        self.weight_decay = trainer_config.get(\"weight_decay\", 3e-4)\n",
    "        self.criterion = trainer_config.get(\"criterion\", F.cross_entropy)\n",
    "        self.patience = trainer_config.get(\"patience\", 3)\n",
    "\n",
    "        # 모델 생성\n",
    "        self.model = Model(**model_config).to(self.device)\n",
    "\n",
    "        optimizer_type = trainer_config.get(\"optimizer\", \"AdamW\")\n",
    "        params = make_parameter_groups(self.model)\n",
    "        if optimizer_type == \"AdamW\":\n",
    "            self.optimizer = torch.optim.AdamW(params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        elif optimizer_type == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(params, lr=self.lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {optimizer_type}\")\n",
    "\n",
    "    def fit(self, train_loader, valid_loader, num_epochs=30, verbose=True):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_epoch = 0\n",
    "        best_auc = 0\n",
    "\n",
    "        best_model_state = None\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for x_num_batch, x_cat_batch, y_batch in train_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                # x_cat_batch가 없는 경우에도 대응 (None 체크)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                # 모델 출력: (batch, k, ?)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                # 앙상블 멤버의 예측값 평균 후, 마지막 차원 제거 (예: (B, 1) -> (B,))\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "            avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "\n",
    "            avg_val_loss = self.evaluate(valid_loader)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping 체크 (validation loss 기준)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = self.model.state_dict()\n",
    "                epochs_without_improvement = 0\n",
    "                best_epoch = epoch\n",
    "                # print(\"  New best validation loss! Model saved.\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                # print(f\"No improvement for {epochs_without_improvement} epoch(s).\")\n",
    "\n",
    "            if epochs_without_improvement >= self.patience:\n",
    "                break\n",
    "\n",
    "        # 학습 종료 후, best model의 가중치를 로드\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(f\"Best model weights loaded from epoch {best_epoch+1} with validation loss {best_val_loss:.4f}.\")\n",
    "\n",
    "        return {\"train_loss_history\": train_loss_history, \"val_loss_history\": val_loss_history}\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        # Validation 단계\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_num_batch, x_cat_batch, y_batch in data_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                val_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(data_loader.dataset)\n",
    "        return avg_val_loss\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                # 배치에 포함된 값의 개수를 확인하여 unpack\n",
    "                if len(batch) == 3:\n",
    "                    x_num_batch, x_cat_batch, _ = batch\n",
    "                elif len(batch) == 2:\n",
    "                    x_num_batch, x_cat_batch = batch\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected number of values in batch\")\n",
    "\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                probs = torch.softmax(ensemble_logits, dim=1)\n",
    "\n",
    "                preds_batch = probs.detach().cpu().numpy()\n",
    "                preds.extend(preds_batch.tolist())\n",
    "        return np.array(preds)\n"
   ],
   "id": "ff599c4b9c777fd3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:11:23.209596Z",
     "start_time": "2025-03-30T02:11:23.194597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_config(n_num_features, cat_cardinalities, bins, arch_type):\n",
    "    model_config = {\n",
    "        'n_num_features': n_num_features,\n",
    "        'cat_cardinalities': cat_cardinalities,\n",
    "        'n_classes': 2,\n",
    "        'backbone': {\n",
    "            'type': 'MLP',\n",
    "            'n_blocks': 3 if bins is None else 2,\n",
    "            'd_block': 512,\n",
    "            'dropout': 0.1,\n",
    "        },\n",
    "        'bins': bins,\n",
    "        'num_embeddings': (\n",
    "            None if bins is None else {\n",
    "                'type': 'PiecewiseLinearEmbeddings',\n",
    "                'd_embedding': 16,\n",
    "                'activation': False,\n",
    "                'version': 'B',\n",
    "            }\n",
    "        ),\n",
    "        'arch_type': arch_type,\n",
    "        'k': 32,\n",
    "        'share_training_batches': True,\n",
    "    }\n",
    "    return model_config\n"
   ],
   "id": "32f926927cf34e34",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.826208Z",
     "start_time": "2025-03-30T02:11:23.226600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed_list = [333]\n",
    "all_auc = []\n",
    "test_preds = []\n",
    "train_history = []\n",
    "\n",
    "for seed in seed_list:\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    auc_scores = []\n",
    "    fold_test_preds = []\n",
    "\n",
    "    train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "    test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "        fold_train, fold_valid = train.iloc[train_idx].copy().reset_index(drop=True), train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "        fold_train2 = fold_train.copy()\n",
    "        fold_test = test.copy()\n",
    "\n",
    "        fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "        fold_train2, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "        cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "        numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "        # TabM\n",
    "        # arch_type = 'tabm'\n",
    "        # bins = None\n",
    "\n",
    "        # TabM-mini with the piecewise-linear embeddings.\n",
    "        arch_type = 'tabm-mini'\n",
    "        bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "        n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "        model_config = get_model_config(n_num_features, cat_cardinalities, bins, arch_type)\n",
    "\n",
    "        trainer_config = {\n",
    "            'device': None,\n",
    "            'optimizer': 'AdamW',\n",
    "            'lr': 2e-3,\n",
    "            'weight_decay': 3e-4,\n",
    "            'criterion': F.cross_entropy,\n",
    "            # 'criterion': F.binary_cross_entropy_with_logits,\n",
    "            'patience': 3,\n",
    "        }\n",
    "\n",
    "        batch_size = 4096\n",
    "        train_loader = to_dataloader(fold_train, batch_size=batch_size)\n",
    "        valid_loader = to_dataloader(fold_valid, batch_size=batch_size, is_shuffle=False)\n",
    "        test_loader = to_dataloader(fold_test, batch_size=batch_size, is_shuffle=False, is_train=False)\n",
    "\n",
    "        model = TabMWrapper(model_config, trainer_config)\n",
    "        history = model.fit(train_loader, valid_loader, verbose=False)\n",
    "        train_history.append(history)\n",
    "\n",
    "        valid_preds = model.predict(valid_loader)[:, 1]\n",
    "        fold_auc = roc_auc_score(fold_valid['임신 성공 여부'], valid_preds)\n",
    "        print(f'Fold {fold + 1} AUC: {fold_auc}')\n",
    "\n",
    "        auc_scores.append(fold_auc)\n",
    "        test_pred = model.predict(test_loader)[:, 1]\n",
    "        fold_test_preds.append(test_pred)\n",
    "\n",
    "    test_preds.append(np.mean(fold_test_preds, axis=0))\n",
    "\n",
    "    # 각 seed별 평균 AUC와 표준편차 출력\n",
    "    seed_auc_mean = np.mean(auc_scores)\n",
    "    seed_auc_std = np.std(auc_scores)\n",
    "    all_auc.append(seed_auc_mean)\n",
    "    print(f\"Seed {seed} - Average AUC: {seed_auc_mean:.5f} (STD: {seed_auc_std:.5f})\")\n",
    "    print('=' * 60)\n",
    "\n",
    "\n",
    "\n",
    "# 전체 결과에 대한 평균 및 표준편차 출력\n",
    "total_auc_mean = np.mean(all_auc)\n",
    "total_auc_std = np.std(all_auc)\n",
    "print('-' * 60)\n",
    "print(f'Total Average AUC: {total_auc_mean:.6f} (STD: {total_auc_std:.6f})')"
   ],
   "id": "e18ee9209a5acd26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights loaded from epoch 5 with validation loss 0.4887.\n",
      "Fold 1 AUC: 0.7404446097407157\n",
      "Best model weights loaded from epoch 6 with validation loss 0.4869.\n",
      "Fold 2 AUC: 0.741742613602096\n",
      "Best model weights loaded from epoch 7 with validation loss 0.4909.\n",
      "Fold 3 AUC: 0.7347143886433024\n",
      "Best model weights loaded from epoch 8 with validation loss 0.4902.\n",
      "Fold 4 AUC: 0.7348754487755882\n",
      "Best model weights loaded from epoch 9 with validation loss 0.4869.\n",
      "Fold 5 AUC: 0.7404747296792731\n",
      "Seed 333 - Average AUC: 0.73845 (STD: 0.00302)\n",
      "============================================================\n",
      "------------------------------------------------------------\n",
      "Total Average AUC: 0.738450 (STD: 0.000000)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.949209Z",
     "start_time": "2025-03-30T02:15:51.934207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "old_auc = 0.744533 * 100\n",
    "old_std = 0.001171 * 100\n",
    "\n",
    "new_auc = total_auc_mean * 100\n",
    "new_std = total_auc_std * 100\n",
    "\n",
    "def calculate_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value) * 100 if old_value != 0 else float('inf')\n",
    "    return change, percentage_change\n",
    "\n",
    "def format_change(change):\n",
    "    return f\"{change:+.6f}\"\n",
    "\n",
    "# 각 지표의 변화량 계산\n",
    "auc_change, auc_pct = calculate_change(old_auc, new_auc)\n",
    "std_change, std_pct = calculate_change(old_std, new_std)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n========== 모델 성능 변화 ==========\")\n",
    "print(f\"{'Metric':<8}  {'AUC':>12}  {'Acc':>12}\")\n",
    "print(\"-\" * 36)\n",
    "print(f\"{'Old':<8}  {old_auc:>12.6f}  {old_std:>12.6f}\")\n",
    "print(f\"{'New':<8}  {new_auc:>12.6f}  {new_std:>12.6f}\")\n",
    "print(f\"{'Change':<8}  {format_change(auc_change):>12}  {format_change(std_change):>12}\")\n",
    "print(f\"{'% Change':<8}  {auc_pct:>11.4f}%  {std_pct:>11.4f}%\")\n",
    "print(\"=\" * 36)"
   ],
   "id": "8b4578cc3b830682",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 모델 성능 변화 ==========\n",
      "Metric             AUC           Acc\n",
      "------------------------------------\n",
      "Old          74.453300      0.117100\n",
      "New          73.845036      0.000000\n",
      "Change       -0.608264     -0.117100\n",
      "% Change      -0.8170%    -100.0000%\n",
      "====================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.996208Z",
     "start_time": "2025-03-30T02:15:51.986207Z"
    }
   },
   "source": [
    "tmp_submission = pd.DataFrame({f'tabm_{data_seed}': np.mean(test_preds, axis=0)})\n",
    "tmp_submission"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        tabm_10\n",
       "0      0.341478\n",
       "1      0.105108\n",
       "2      0.000232\n",
       "3      0.114351\n",
       "4      0.446093\n",
       "...         ...\n",
       "51266  0.231313\n",
       "51267  0.255745\n",
       "51268  0.141795\n",
       "51269  0.029850\n",
       "51270  0.151660\n",
       "\n",
       "[51271 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabm_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51266</th>\n",
       "      <td>0.231313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0.255745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51268</th>\n",
       "      <td>0.141795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>0.029850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>0.151660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51271 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.055439Z",
     "start_time": "2025-03-30T02:15:52.091208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "\n",
    "score = calculate_auc(tmp_submission, seed=data_seed)\n",
    "print(f'[seed {data_seed}]: {score}')"
   ],
   "id": "a64672a7154d813d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 10]: 0.74150757679765\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.117442Z",
     "start_time": "2025-03-30T02:15:53.103441Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "189382d5401e8bc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
