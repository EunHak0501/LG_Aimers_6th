{
 "cells": [
  {
   "cell_type": "code",
   "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:01.904449Z",
     "start_time": "2025-04-05T08:07:59.828562Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, accuracy_score\n",
    "\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import rtdl_num_embeddings\n",
    "from tqdm import tqdm\n",
    "from typing import Literal, NamedTuple\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:02.327392Z",
     "start_time": "2025-04-05T08:08:01.908448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_path = '../offline_data/train_aimers_6th_offline.csv'\n",
    "test_path = '../offline_data/test_aimers_6th_offline.csv'\n",
    "sample_path = '../offline_data/sample_submission_aimers_6th_offline.csv'\n",
    "\n",
    "train = pd.read_csv(train_path, encoding='utf-8-sig').drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path, encoding='utf-8-sig').drop(columns=['ID'])\n",
    "\n",
    "task_type = 'regression'\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "id": "2c1e10fa54d4f77a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126244, 34) (54412, 33)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:02.484392Z",
     "start_time": "2025-04-05T08:08:02.471392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_list = train.columns.tolist()\n",
    "cols_list"
   ],
   "id": "519257af24cede5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['환자 시술 당시 나이',\n",
       " '시술 유형',\n",
       " '세부 시술 유형',\n",
       " '배란 자극 시술 여부',\n",
       " '단일 배아 이식 여부',\n",
       " '불임 원인 - 난관 질환',\n",
       " '불임 원인 - 배란 장애',\n",
       " '불임 원인 - 남성 요인',\n",
       " '불임 원인 - 자궁내막증',\n",
       " '불임 원인 - 불명확',\n",
       " '이전 IVF 시술 횟수',\n",
       " '이전 DI 시술 횟수',\n",
       " '이전 총 임신 횟수',\n",
       " '이전 총 임신 성공 횟수',\n",
       " '총 생성 배아 수',\n",
       " '이식된 배아 수',\n",
       " '미세주입(ICSI) 배아 이식 수',\n",
       " '저장된 배아 수',\n",
       " '해동된 배아 수',\n",
       " '해동 난자 사용 여부',\n",
       " '채취된 신선 난자 수',\n",
       " '신선 난자 사용 여부',\n",
       " '수정 시도된 난자 수',\n",
       " '난자 출처',\n",
       " '정자 출처',\n",
       " '난자 기증자 나이',\n",
       " '정자 기증자 나이',\n",
       " '동결 배아 사용 여부',\n",
       " '신선 배아 사용 여부',\n",
       " '기증 배아 사용 여부',\n",
       " '착상 전 PGD 시행 여부',\n",
       " '착상 전 PGS 시행 여부',\n",
       " '배아 이식 후 경과일',\n",
       " '임신 성공 확률']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:02.531393Z",
     "start_time": "2025-04-05T08:08:02.506393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, QuantileTransformer, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "def drop_cols_with_na(train_df, val_df):\n",
    "    # 나중에 결측치 대체하면서 반영할 예정\n",
    "\n",
    "    cat_cols_with_na = [\n",
    "        '이전 총 임신 횟수',\n",
    "        '이전 총 임신 성공 횟수',\n",
    "\n",
    "        '총 생성 배아 수', ## 여기부터 100% DI\n",
    "        '저장된 배아 수',\n",
    "        '채취된 신선 난자 수',\n",
    "        '수정 시도된 난자 수'\n",
    "    ]\n",
    "\n",
    "    numeric_cols_with_na = [\n",
    "        '이식된 배아 수', ## only DI\n",
    "        '미세주입(ICSI) 배아 이식 수',\n",
    "        '배아 이식 후 경과일',\n",
    "    ]\n",
    "    train_df = train_df.drop(columns=cat_cols_with_na)\n",
    "    train_df = train_df.drop(columns=numeric_cols_with_na)\n",
    "    val_df = val_df.drop(columns=cat_cols_with_na)\n",
    "    val_df = val_df.drop(columns=numeric_cols_with_na)\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def 시술유형(train, test):\n",
    "    train['세부 시술 유형'] = train['세부 시술 유형'].fillna(\"Unknown\")\n",
    "    test['세부 시술 유형'] = test['세부 시술 유형'].fillna(\"Unknown\")\n",
    "\n",
    "    def categorize_procedure(proc):\n",
    "        tokens = [token.strip() for token in proc.split(\",\") if token.strip() and not token.strip().isdigit()]\n",
    "        # 우선순위에 따른 범주화\n",
    "        if tokens.count(\"Unknown\") >= 1:\n",
    "            return \"Unknown\"\n",
    "        if tokens.count(\"AH\") >= 1:\n",
    "            return \"AH\"\n",
    "        if tokens.count(\"BLASTOCYST\") >= 1:\n",
    "            return \"BLASTOCYST\"\n",
    "        if tokens.count(\"ICSI\") >= 2 or tokens.count(\"IVF\") >= 2:\n",
    "            return \"2ICSI_2IVF\"\n",
    "        if tokens.count(\"IVF\") >= 1 and tokens.count(\"ICSI\") >= 1:\n",
    "            return \"IVF_ICSI\"\n",
    "        if tokens == \"ICSI\":\n",
    "            return \"ICSI\"\n",
    "        if tokens == \"IVF\":\n",
    "            return \"IVF\"\n",
    "        return \",\".join(tokens) if tokens else None\n",
    "\n",
    "    for df in [train, test]:\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\" / \", \",\")\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\":\", \",\")\n",
    "        df['세부 시술 유형'] = df['세부 시술 유형'].str.replace(\" \", \"\")\n",
    "\n",
    "    counts = train['세부 시술 유형'].value_counts()\n",
    "    allowed_categories = counts[counts >= 100].index.tolist()\n",
    "\n",
    "    # allowed_categories에 속하지 않는 값은 \"Unknown\"으로 대체\n",
    "    train.loc[~train['세부 시술 유형'].isin(allowed_categories), '세부 시술 유형'] = \"Unknown\"\n",
    "    test.loc[~test['세부 시술 유형'].isin(allowed_categories), '세부 시술 유형'] = \"Unknown\"\n",
    "\n",
    "    train['세부 시술 유형'] = train['세부 시술 유형'].apply(categorize_procedure)\n",
    "    test['세부 시술 유형'] = test['세부 시술 유형'].apply(categorize_procedure)\n",
    "\n",
    "    train['시술유형_통합'] = train['시술 유형'].astype(str) + '_' + train['세부 시술 유형'].astype(str)\n",
    "    test['시술유형_통합'] = test['시술 유형'].astype(str) + '_' + test['세부 시술 유형'].astype(str)\n",
    "\n",
    "    drop_cols = ['시술 유형', '세부 시술 유형']\n",
    "    train = train.drop(drop_cols, axis=1)\n",
    "    test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def 횟수_to_int(df_train, df_val):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상': '6회'})\n",
    "        df_val[col] = df_val[col].replace({'6회 이상': '6회'})\n",
    "\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "        df_val[col] = df_val[col].str[0].astype(int)\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "def 임신_IVF(df_train, df_val):\n",
    "    for col in [col for col in df_train.columns if '횟수' in col]:\n",
    "        df_train[col] = df_train[col].replace({'6회 이상': '6회'})\n",
    "        df_val[col] = df_val[col].replace({'6회 이상': '6회'})\n",
    "        mode_value = df_train[col].mode()[0]\n",
    "\n",
    "        df_train[col] = df_train[col].fillna(mode_value)\n",
    "        df_val[col] = df_val[col].fillna(mode_value)\n",
    "\n",
    "        # 문자열의 첫 글자를 추출 후 int형으로 변환\n",
    "        df_train[col] = df_train[col].str[0].astype(int)\n",
    "        df_val[col] = df_val[col].str[0].astype(int)\n",
    "\n",
    "    df_train['임신_IVF'] = df_train['이전 총 임신 횟수'] - df_train['이전 IVF 시술 횟수']\n",
    "    df_val['임신_IVF'] = df_val['이전 총 임신 횟수'] - df_val['이전 IVF 시술 횟수']\n",
    "    # df_train = df_train.drop('이전 시술 횟수', axis=1)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def 난자기증자나이(df_train, df_test):\n",
    "    mapping = {\n",
    "        '만20세 이하': 20,\n",
    "        '만21-25세': 25,\n",
    "        '만26-30세': 30,\n",
    "        '만31-35세': 35,\n",
    "        '알 수 없음': 20,  # 만20세 이하와 동일하게 처리\n",
    "    }\n",
    "    df_train['난자 기증자 나이'] = df_train['난자 기증자 나이'].replace(mapping)\n",
    "    df_test['난자 기증자 나이'] = df_test['난자 기증자 나이'].replace(mapping)\n",
    "    return df_train, df_test\n",
    "\n",
    "def 단일배아이식여부(df_train, df_val):\n",
    "    df_train['단일 배아 이식 여부'] = df_train['단일 배아 이식 여부'].fillna(0)\n",
    "    df_val['단일 배아 이식 여부'] = df_val['단일 배아 이식 여부'].fillna(0)\n",
    "    return df_train, df_val\n",
    "\n",
    "\n",
    "def 기증자정자와혼합된난자수(df_train, df_test):\n",
    "    df_train[\"기증자 정자와 혼합된 난자 수\"] = df_train[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    df_test[\"기증자 정자와 혼합된 난자 수\"] = df_test[\"기증자 정자와 혼합된 난자 수\"].fillna(2)\n",
    "    return df_train, df_test\n",
    "\n",
    "def label_encoding(train, test, cols):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cols:\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        test[col] = encoder.transform(test[col])\n",
    "    return train, test\n",
    "\n",
    "def type_to_category(train, test, cols):\n",
    "    train[cols] = train[cols].astype('category')\n",
    "    test[cols] = test[cols].astype('category')\n",
    "    return train, test\n",
    "\n",
    "def impute_nan(train, test):\n",
    "\n",
    "    for col in cols_to_impute:\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def num_feature_scailing(train, test, seed=777):\n",
    "    cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "    numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 확률']\n",
    "    # bin_cols 들도 동일하게 스케일링\n",
    "\n",
    "    arr_train = train[numeric_cols].to_numpy()  # DataFrame -> NumPy\n",
    "    arr_train = arr_train.astype(np.float32)\n",
    "    arr_test = test[numeric_cols].to_numpy()\n",
    "    arr_test = arr_test.astype(np.float32)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    noise = (\n",
    "        np.random.default_rng(0)\n",
    "        .normal(0.0, 1e-5, arr_train.shape)\n",
    "        .astype(arr_train.dtype)\n",
    "    )\n",
    "    preprocessing = QuantileTransformer(\n",
    "        n_quantiles=max(min(len(train[numeric_cols]) // 30, 1000), 10),\n",
    "        output_distribution='normal',\n",
    "        subsample=10**9,\n",
    "    ).fit(arr_train + noise)\n",
    "\n",
    "    train[numeric_cols] = preprocessing.transform(arr_train)\n",
    "    test[numeric_cols] = preprocessing.transform(arr_test)\n",
    "    return train, test\n",
    "\n",
    "def drop_single_value_columns(df_train, df_test):\n",
    "    cols_to_drop = [col for col in df_train.columns if df_train[col].nunique() == 1]\n",
    "    return df_train.drop(columns=cols_to_drop), df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "def all_process(train, val):\n",
    "    train, val = drop_cols_with_na(train, val)\n",
    "\n",
    "    # 기본 전처리 단계\n",
    "    train, val = 횟수_to_int(train, val)\n",
    "\n",
    "    train, val = 시술유형(train, val)\n",
    "    # train, val = 임신_IVF(train, val)\n",
    "\n",
    "    train, val = 단일배아이식여부(train, val)\n",
    "\n",
    "    cols_to_encoding = [\n",
    "        \"환자 시술 당시 나이\",\n",
    "        # \"클리닉 내 총 시술 횟수\",\n",
    "        # \"IVF 시술 횟수\",\n",
    "        # \"DI 시술 횟수\",\n",
    "        # \"총 임신 횟수\",\n",
    "        # \"IVF 임신 횟수\",\n",
    "        # \"DI 임신 횟수\",\n",
    "        # \"총 출산 횟수\",\n",
    "        # \"IVF 출산 횟수\",\n",
    "        # \"DI 출산 횟수\",\n",
    "        \"난자 출처\",\n",
    "        \"정자 출처\",\n",
    "        \"난자 기증자 나이\",\n",
    "        \"정자 기증자 나이\",\n",
    "        '시술유형_통합',\n",
    "\n",
    "        '해동된 배아 수', # 원래 int였는데 범주형으로 바뀜\n",
    "\n",
    "    ]\n",
    "    train, val = label_encoding(train, val, cols=cols_to_encoding)\n",
    "    train, val = type_to_category(train, val, cols=cols_to_encoding)\n",
    "\n",
    "    # train, val = impute_nan(train, val)\n",
    "    train, val = num_feature_scailing(train, val)\n",
    "\n",
    "    train, val = drop_single_value_columns(train, val)\n",
    "\n",
    "    return train, val\n"
   ],
   "id": "286dba17a329fbec",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "63299de32ba2bec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:03.801047Z",
     "start_time": "2025-04-05T08:08:02.564394Z"
    }
   },
   "source": [
    "# from preprocess_DL_offline import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 확률']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 16개 \n",
      "['배란 자극 시술 여부', '단일 배아 이식 여부', '불임 원인 - 난관 질환', '불임 원인 - 배란 장애', '불임 원인 - 남성 요인', '불임 원인 - 자궁내막증', '불임 원인 - 불명확', '이전 IVF 시술 횟수', '이전 DI 시술 횟수', '해동 난자 사용 여부', '신선 난자 사용 여부', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '착상 전 PGD 시행 여부', '착상 전 PGS 시행 여부']\n",
      "범주형 변수: 7개 \n",
      "['환자 시술 당시 나이', '해동된 배아 수', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(126244, 24) (54412, 23)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7175bdaadb738a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:03.817048Z",
     "start_time": "2025-04-05T08:08:03.804047Z"
    }
   },
   "source": [
    "def df_to_tensor(train, val, test=None):\n",
    "    if test is None:\n",
    "        data_numpy = {\n",
    "            'train': {\n",
    "                'x_cat': train[cat_cols].apply(lambda col: col.astype('category').cat.codes.astype(np.int64)).values,\n",
    "                'x_cont': train[numeric_cols].values,\n",
    "                'y': train['임신 성공 확률'].values,\n",
    "            },\n",
    "            'val': {\n",
    "                'x_cat': val[cat_cols].apply(lambda col: col.astype('category').cat.codes.astype(np.int64)).values,\n",
    "                'x_cont': val[numeric_cols].values,\n",
    "                'y': val['임신 성공 확률'].values,\n",
    "            },\n",
    "        }\n",
    "        data = {\n",
    "            part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "            for part in data_numpy\n",
    "        }\n",
    "        data['train']['y'] = data['train']['y'].float()\n",
    "        data['val']['y'] = data['val']['y'].float()\n",
    "        return data\n",
    "    else:\n",
    "        data_numpy = {\n",
    "            'train': {\n",
    "                'x_cat': train[cat_cols].apply(lambda col: col.astype('category').cat.codes.astype(np.int64)).values,\n",
    "                'x_cont': train[numeric_cols].values,\n",
    "                'y': train['임신 성공 확률'].values,\n",
    "            },\n",
    "            'val': {\n",
    "                'x_cat': val[cat_cols].apply(lambda col: col.astype('category').cat.codes.astype(np.int64)).values,\n",
    "                'x_cont': val[numeric_cols].values,\n",
    "                'y': val['임신 성공 확률'].values,\n",
    "            },\n",
    "            'test': {\n",
    "                'x_cat': test[cat_cols].apply(lambda col: col.astype('category').cat.codes.astype(np.int64)).values,\n",
    "                'x_cont': test[numeric_cols].values,\n",
    "            },\n",
    "        }\n",
    "        data = {\n",
    "            part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
    "            for part in data_numpy\n",
    "        }\n",
    "        data['train']['y'] = data['train']['y'].float()\n",
    "        data['val']['y'] = data['val']['y'].float()\n",
    "        return data"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ff599c4b9c777fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:03.974045Z",
     "start_time": "2025-04-05T08:08:03.835049Z"
    }
   },
   "source": [
    "def get_feature_info(train):\n",
    "    n_num_features_ = len(numeric_cols)\n",
    "    cat_cardinalities_ = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return n_num_features_, cat_cardinalities_\n",
    "\n",
    "n_num_features, cat_cardinalities = get_feature_info(train)\n",
    "bins = rtdl_num_embeddings.compute_bins(torch.tensor(train[numeric_cols].values))\n",
    "\n",
    "model_config = {\n",
    "    'n_num_features': n_num_features,\n",
    "    'cat_cardinalities': cat_cardinalities,\n",
    "    'n_classes': 1,  # 회귀 > 1, 분류 > 2\n",
    "    'backbone': {\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 3 if bins is None else 2,\n",
    "        'd_block': 512,\n",
    "        'dropout': 0.1,\n",
    "    },\n",
    "    'bins': bins,\n",
    "    'num_embeddings': (\n",
    "        None if bins is None else {\n",
    "            'type': 'PiecewiseLinearEmbeddings',\n",
    "            'd_embedding': 16,\n",
    "            'activation': False,\n",
    "            'version': 'B',\n",
    "        }\n",
    "    ),\n",
    "    'arch_type': 'tabm-mini',\n",
    "    'k': 32,\n",
    "    'share_training_batches': True,\n",
    "}\n",
    "\n",
    "model = Model(**model_config).to(device)\n",
    "\n",
    "print(n_num_features)\n",
    "print(cat_cardinalities)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[7, 4, 3, 5, 6, 8, 8]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "32f926927cf34e34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:04.880524Z",
     "start_time": "2025-04-05T08:08:04.036044Z"
    }
   },
   "source": [
    "optimizer = torch.optim.AdamW(make_parameter_groups(model), lr=2e-3, weight_decay=3e-4)\n",
    "optimizer = torch.optim.Adam(make_parameter_groups(model), lr=2e-3)\n",
    "\n",
    "base_loss_fn = F.mse_loss\n",
    "\n",
    "def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
    "    # TabM produces k predictions. Each of them must be trained separately.\n",
    "    # (regression)     y_pred.shape == (batch_size, k)\n",
    "    # (classification) y_pred.shape == (batch_size, k, n_classes)\n",
    "    k = y_pred.shape[-1 if task_type == 'regression' else -2]\n",
    "    return base_loss_fn(\n",
    "        y_pred.flatten(0, 1),\n",
    "        y_true.repeat_interleave(k) if model.share_training_batches else y_true,\n",
    "    )\n",
    "\n",
    "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
    "    return (\n",
    "        model(\n",
    "            data[part]['x_cont'][idx],\n",
    "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
    "        )\n",
    "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
    "        .float()\n",
    "    )\n",
    "\n",
    "class RegressionLabelStats(NamedTuple):\n",
    "    mean: float\n",
    "    std: float\n",
    "\n",
    "def evaluate(part: str) -> float:\n",
    "    model.eval()\n",
    "    eval_batch_size = 2048\n",
    "    y_pred: np.ndarray = (\n",
    "        torch.cat(\n",
    "            [\n",
    "                apply_model(part, idx)\n",
    "                for idx in torch.arange(len(data[part]['y']), device=device).split(\n",
    "                eval_batch_size\n",
    "            )\n",
    "            ]\n",
    "        )\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if task_type == 'regression':\n",
    "        # Transform the predictions back to the original label space.\n",
    "        assert regression_label_stats is not None\n",
    "        y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
    "\n",
    "    # Compute the mean of the k predictions.\n",
    "    if task_type != 'regression':\n",
    "        y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "    y_pred = y_pred.mean(1)\n",
    "\n",
    "    y_true = data[part]['y'].cpu().numpy()\n",
    "    score = (\n",
    "        -(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "        if task_type == 'regression'\n",
    "        else accuracy_score(y_true, y_pred.argmax(1))\n",
    "    )\n",
    "    return float(score)\n",
    "\n",
    "\n",
    "def predict_proba(part: str) -> np.ndarray:\n",
    "    model.eval()\n",
    "    eval_batch_size = 2048\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        num_samples = len(data[part]['x_cont'])\n",
    "        for idx in torch.arange(num_samples, device=device).split(eval_batch_size):\n",
    "            batch_pred = apply_model(part, idx)\n",
    "            preds.append(batch_pred)\n",
    "\n",
    "    # 모든 배치의 예측값을 하나의 텐서로 합칩니다.\n",
    "    y_pred = torch.cat(preds).cpu().numpy()\n",
    "\n",
    "    # 회귀 문제라면 regression_label_stats를 사용하여 원래 label space로 변환합니다.\n",
    "    if task_type == 'regression':\n",
    "        assert regression_label_stats is not None\n",
    "        y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
    "    else:\n",
    "        y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
    "\n",
    "    # k개의 예측값에 대해 평균을 냅니다.\n",
    "    y_pred = y_pred.mean(axis=1)\n",
    "\n",
    "    # 마지막 축의 크기가 1이면 squeeze 처리합니다.\n",
    "    if y_pred.ndim > 1 and y_pred.shape[-1] == 1:\n",
    "        y_pred = y_pred.squeeze(-1)\n",
    "\n",
    "    return y_pred"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:04.927523Z",
     "start_time": "2025-04-05T08:08:04.913524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 자동 혼합 정밀도(AMP)에서 사용할 데이터 타입(amp_dtype)을 설정합니다.\n",
    "if torch.cuda.is_available():\n",
    "    # CUDA를 사용할 수 있으면, bfloat16 지원 여부를 확인합니다.\n",
    "    if torch.cuda.is_bf16_supported():\n",
    "        amp_dtype = torch.bfloat16  # bfloat16을 지원하면 bfloat16을 사용합니다.\n",
    "    else:\n",
    "        amp_dtype = torch.float16   # bfloat16을 지원하지 않으면 float16을 사용합니다.\n",
    "else:\n",
    "    amp_dtype = None  # CUDA를 사용할 수 없으면 AMP를 사용하지 않습니다.\n",
    "\n",
    "# 2. AMP 기능을 활성화할지 결정합니다.\n",
    "amp_enabled = False and (amp_dtype is not None)\n",
    "\n",
    "# 3. GradScaler는 float16 모드에서 수치 안정성을 위해 사용됩니다.\n",
    "# amp_dtype이 torch.float16일 때만 GradScaler를 생성합니다.\n",
    "if amp_dtype == torch.float16:\n",
    "    grad_scaler = torch.cuda.amp.GradScaler()\n",
    "else:\n",
    "    grad_scaler = None\n",
    "\n",
    "print(grad_scaler)"
   ],
   "id": "e29f831df3bcd7eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:04.975526Z",
     "start_time": "2025-04-05T08:08:04.960525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def f1_score(true_prob, pred_prob):\n",
    "    true_binary = (np.array(true_prob) > 0.5).astype(int)\n",
    "    pred_binary = (np.array(pred_prob) > 0.5).astype(int)\n",
    "    return metrics.f1_score(true_binary, pred_binary)\n",
    "\n",
    "def weighted_brier_score(true_prob, pred_prob, alpha=4):\n",
    "    weights = 1 + alpha * true_prob + np.abs(0.5 - true_prob) ** 2\n",
    "    brier = np.sum(weights * (true_prob - pred_prob) ** 2) / np.sum(weights)\n",
    "    adjusted_brier = max(0, 1 - brier)\n",
    "    return adjusted_brier\n",
    "\n",
    "def competition_metric(true_prob, pred_prob):\n",
    "    true_prob = np.array(true_prob)\n",
    "    pred_prob = np.array(pred_prob)\n",
    "\n",
    "    if true_prob.shape != pred_prob.shape:\n",
    "        raise ValueError(\"예측값과 정답값의 shape이 일치하지 않습니다.\")\n",
    "    if np.isnan(pred_prob).any():\n",
    "        raise ValueError(\"예측값에 NaN이 포함되어 있습니다.\")\n",
    "    if not ((0 <= pred_prob) & (pred_prob <= 1)).all():\n",
    "        raise ValueError(\"예측값이 0~1 범위를 벗어났습니다.\")\n",
    "    if not np.isfinite(pred_prob).all():\n",
    "        raise ValueError(\"예측값에 inf 또는 -inf가 포함되어 있습니다.\")\n",
    "\n",
    "    wbs = weighted_brier_score(true_prob, pred_prob)\n",
    "    f1 = f1_score(true_prob, pred_prob)\n",
    "    score = 0.5 * wbs + 0.5 * f1\n",
    "    return score"
   ],
   "id": "5897a3fc1926b747",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e18ee9209a5acd26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:12:41.912370Z",
     "start_time": "2025-04-05T08:10:39.311457Z"
    }
   },
   "source": [
    "seed = 333\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "test_preds = []\n",
    "val_scores = []\n",
    "val_aucs = []\n",
    "\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(train)):\n",
    "    fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "    fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "    fold_train2 = fold_train.copy()\n",
    "    fold_test = test.copy()\n",
    "\n",
    "    fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "    _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "    Y_train = fold_train['임신 성공 확률'].copy()\n",
    "    if task_type == 'regression':\n",
    "        regression_label_stats = RegressionLabelStats(\n",
    "            Y_train.mean().item(), Y_train.std().item()\n",
    "        )\n",
    "        Y_train = (Y_train - regression_label_stats.mean) / regression_label_stats.std\n",
    "    else:\n",
    "        regression_label_stats = None\n",
    "\n",
    "    Y_train = torch.as_tensor(Y_train.values, device=device, dtype=torch.float)\n",
    "\n",
    "    cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "    numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 확률']\n",
    "\n",
    "    bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "    n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "\n",
    "    model_config = {\n",
    "        'n_num_features': n_num_features,\n",
    "        'cat_cardinalities': cat_cardinalities,\n",
    "        'n_classes': 1,\n",
    "        'backbone': {\n",
    "            'type': 'MLP',\n",
    "            'n_blocks': 3 if bins is None else 2,\n",
    "            'd_block': 512,\n",
    "            'dropout': 0.1,\n",
    "        },\n",
    "        'bins': bins,\n",
    "        'num_embeddings': (\n",
    "            None if bins is None else {\n",
    "                'type': 'PiecewiseLinearEmbeddings',\n",
    "                'd_embedding': 16,\n",
    "                'activation': False,\n",
    "                'version': 'B',\n",
    "            }\n",
    "        ),\n",
    "        'arch_type': 'tabm-mini',\n",
    "        'k': 32,\n",
    "        'share_training_batches': True,\n",
    "    }\n",
    "    model = Model(**model_config).to(device)\n",
    "\n",
    "    data = df_to_tensor(fold_train, fold_valid, fold_test)\n",
    "\n",
    "    n_epochs = 1_000_000_000\n",
    "    patience = 16\n",
    "\n",
    "    train_size = len(train_idx)\n",
    "    batch_size = 256\n",
    "    epoch_size = math.ceil(train_size / batch_size)\n",
    "    best = {\n",
    "        'val': -math.inf,\n",
    "        'epoch': -1,\n",
    "    }\n",
    "\n",
    "    patience = 16\n",
    "    remaining_patience = patience\n",
    "\n",
    "    print('-' * 88 + '\\n')\n",
    "    for epoch in range(n_epochs):\n",
    "        batches = (\n",
    "            torch.randperm(train_size, device=device).split(batch_size)\n",
    "            if model.share_training_batches\n",
    "            else [\n",
    "                x.transpose(0, 1).flatten()\n",
    "                for x in torch.rand((model.k, train_size), device=device)\n",
    "                .argsort(dim=1)\n",
    "                .split(batch_size, dim=1)\n",
    "            ]\n",
    "        )\n",
    "        for batch_idx in batches:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(apply_model('train', batch_idx), Y_train[batch_idx])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_score = evaluate('val')\n",
    "        print(f'[Fold {fold} epoch {epoch}] (val) {val_score}')\n",
    "\n",
    "        if val_score > best['val']:\n",
    "            best = {'val': val_score, 'epoch': epoch}\n",
    "            remaining_patience = patience\n",
    "        else:\n",
    "            remaining_patience -= 1\n",
    "\n",
    "        if remaining_patience < 0:\n",
    "            break\n",
    "\n",
    "    print('\\nResult:')\n",
    "    print(best)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    print(\"Best model weights loaded from best_model.pt\")\n",
    "\n",
    "    y_val_pred = predict_proba('val')\n",
    "    val_score = competition_metric(fold_valid['임신 성공 확률'], y_val_pred)\n",
    "    val_scores.append(val_score)\n",
    "    print(val_score)\n",
    "\n",
    "    y_test_pred = predict_proba('test')\n",
    "    test_preds.append(y_test_pred)\n",
    "\n",
    "final_valid_score = np.mean(val_scores)\n",
    "print(f'[Seed {seed}] Validation Score: {final_valid_score}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "[Fold 0] (val) -0.4144102112091948\n",
      "\n",
      "Result:\n",
      "{'val': -0.4144102112091948, 'epoch': 0}\n",
      "Best model weights loaded from best_model.pt\n",
      "0.34655445514062444\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "[Fold 1] (val) -0.41248568307711153\n",
      "\n",
      "Result:\n",
      "{'val': -0.41248568307711153, 'epoch': 0}\n",
      "Best model weights loaded from best_model.pt\n",
      "0.34805004120879757\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "[Fold 2] (val) -0.4142748989698335\n",
      "\n",
      "Result:\n",
      "{'val': -0.4142748989698335, 'epoch': 0}\n",
      "Best model weights loaded from best_model.pt\n",
      "0.34705539997776946\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "[Fold 3] (val) -0.4146303206163646\n",
      "\n",
      "Result:\n",
      "{'val': -0.4146303206163646, 'epoch': 0}\n",
      "Best model weights loaded from best_model.pt\n",
      "0.34652279807192976\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "[Fold 4] (val) -0.41503861371184375\n",
      "\n",
      "Result:\n",
      "{'val': -0.41503861371184375, 'epoch': 0}\n",
      "Best model weights loaded from best_model.pt\n",
      "0.3463481690832086\n",
      "[Seed 333] Validation Score: 0.346906172696466\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:37:17.996217600Z",
     "start_time": "2025-04-05T06:33:07.608127Z"
    }
   },
   "source": [
    "submission = pd.read_csv(sample_path)\n",
    "\n",
    "submission['probability'] = np.mean(test_preds, axis=0)\n",
    "submission"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               ID  임신 성공 확률  probability\n",
       "0      TEST_00000         0          NaN\n",
       "1      TEST_00001         0          NaN\n",
       "2      TEST_00002         0          NaN\n",
       "3      TEST_00003         0          NaN\n",
       "4      TEST_00004         0          NaN\n",
       "...           ...       ...          ...\n",
       "54407  TEST_54407         0          NaN\n",
       "54408  TEST_54408         0          NaN\n",
       "54409  TEST_54409         0          NaN\n",
       "54410  TEST_54410         0          NaN\n",
       "54411  TEST_54411         0          NaN\n",
       "\n",
       "[54412 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>임신 성공 확률</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54407</th>\n",
       "      <td>TEST_54407</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54408</th>\n",
       "      <td>TEST_54408</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54409</th>\n",
       "      <td>TEST_54409</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54410</th>\n",
       "      <td>TEST_54410</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54411</th>\n",
       "      <td>TEST_54411</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54412 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64672a7154d813d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:37:17.997216400Z",
     "start_time": "2025-03-30T02:15:52.091208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 10]: 0.74150757679765\n"
     ]
    }
   ],
   "source": "submission.to_csv(f'TabM_{seed}.csv', index=False, encoding='utf-8-sig')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189382d5401e8bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T07:37:17.997216400Z",
     "start_time": "2025-03-30T02:15:53.103441Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
