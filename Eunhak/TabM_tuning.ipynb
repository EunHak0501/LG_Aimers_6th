{
 "cells": [
  {
   "cell_type": "code",
   "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:12:52.976727Z",
     "start_time": "2025-04-01T09:12:50.658717Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import rtdl_num_embeddings\n",
    "import optuna\n",
    "\n",
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:13:07.276870Z",
     "start_time": "2025-04-01T09:13:06.346208Z"
    }
   },
   "source": [
    "data_seed = 10\n",
    "\n",
    "train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:13:11.919097Z",
     "start_time": "2025-04-01T09:13:07.293871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from preprocess_DL import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ],
   "id": "398c6a23d4086d96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 57개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:13:12.029095Z",
     "start_time": "2025-04-01T09:13:11.951096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feature_info(train, target_col='임신 성공 여부'):\n",
    "    n_num_features_ = len(numeric_cols)\n",
    "    cat_cardinalities_ = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return n_num_features_, cat_cardinalities_\n",
    "\n",
    "def to_dataloader(df, batch_size=256, is_shuffle=True, is_train=True, target_col='임신 성공 여부'):\n",
    "    X_num = torch.tensor(df[numeric_cols].values, dtype=torch.float32)\n",
    "    X_cat = torch.tensor(df[cat_cols].values, dtype=torch.long)\n",
    "\n",
    "    if is_train:\n",
    "        y = torch.tensor(df[target_col].values, dtype=torch.float32)\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat, y)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "    else:\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "n_num_features, cat_cardinalities = get_feature_info(train)\n",
    "print(n_num_features)\n",
    "print(cat_cardinalities)\n",
    "\n",
    "train_loader = to_dataloader(train)\n",
    "test_loader = to_dataloader(test, is_shuffle=False, is_train=False)"
   ],
   "id": "7175bdaadb738a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "[7, 7, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:13:12.060095Z",
     "start_time": "2025-04-01T09:13:12.045095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabMWrapper:\n",
    "    def __init__(self, model_config, trainer_config):\n",
    "        self.device = trainer_config.get(\"device\") or torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        self.lr = trainer_config.get(\"lr\", 0.001)\n",
    "        self.weight_decay = trainer_config.get(\"weight_decay\", 3e-4)\n",
    "        self.criterion = trainer_config.get(\"criterion\", F.cross_entropy)\n",
    "        self.patience = trainer_config.get(\"patience\", 3)\n",
    "\n",
    "        # 모델 생성\n",
    "        self.model = Model(**model_config).to(self.device)\n",
    "\n",
    "        optimizer_type = trainer_config.get(\"optimizer\", \"AdamW\")\n",
    "        params = make_parameter_groups(self.model)\n",
    "        if optimizer_type == \"AdamW\":\n",
    "            self.optimizer = torch.optim.AdamW(params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        elif optimizer_type == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(params, lr=self.lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {optimizer_type}\")\n",
    "\n",
    "    def fit(self, train_loader, valid_loader, num_epochs=30, verbose=True):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_epoch = 0\n",
    "        best_auc = 0\n",
    "\n",
    "        best_model_state = None\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for x_num_batch, x_cat_batch, y_batch in train_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                # x_cat_batch가 없는 경우에도 대응 (None 체크)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                # 모델 출력: (batch, k, ?)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                # 앙상블 멤버의 예측값 평균 후, 마지막 차원 제거 (예: (B, 1) -> (B,))\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "            avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "\n",
    "            avg_val_loss = self.evaluate(valid_loader)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping 체크 (validation loss 기준)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = self.model.state_dict()\n",
    "                epochs_without_improvement = 0\n",
    "                best_epoch = epoch\n",
    "                # print(\"  New best validation loss! Model saved.\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                # print(f\"No improvement for {epochs_without_improvement} epoch(s).\")\n",
    "\n",
    "            if epochs_without_improvement >= self.patience:\n",
    "                break\n",
    "\n",
    "        # 학습 종료 후, best model의 가중치를 로드\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            # print(f\"Best model weights loaded from epoch {best_epoch+1} with validation loss {best_val_loss:.4f}.\")\n",
    "\n",
    "        return {\"train_loss_history\": train_loss_history, \"val_loss_history\": val_loss_history}\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        # Validation 단계\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_num_batch, x_cat_batch, y_batch in data_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                val_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(data_loader.dataset)\n",
    "        return avg_val_loss\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                # 배치에 포함된 값의 개수를 확인하여 unpack\n",
    "                if len(batch) == 3:\n",
    "                    x_num_batch, x_cat_batch, _ = batch\n",
    "                elif len(batch) == 2:\n",
    "                    x_num_batch, x_cat_batch = batch\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected number of values in batch\")\n",
    "\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                probs = torch.softmax(ensemble_logits, dim=1)\n",
    "\n",
    "                preds_batch = probs.detach().cpu().numpy()\n",
    "                preds.extend(preds_batch.tolist())\n",
    "        return np.array(preds)\n"
   ],
   "id": "ff599c4b9c777fd3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T09:12:17.839966Z",
     "start_time": "2025-04-01T09:12:17.765967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 333\n",
    "all_auc_val = []\n",
    "all_auc_test = []\n",
    "test_preds = []\n",
    "train_history = []\n",
    "\n",
    "\n",
    "data_seeds = [1, 7]\n",
    "for data_seed in data_seeds:\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "    test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "    train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "    test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "    fold_test_preds = []\n",
    "    auc_scores = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "        fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "        fold_train2 = fold_train.copy()\n",
    "        fold_test = test.copy()\n",
    "\n",
    "        fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "        _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "        cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "        numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "        arch_type = 'tabm-mini'\n",
    "        bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "        bins = None\n",
    "        n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "        model_config = {\n",
    "            'n_num_features': n_num_features,\n",
    "            'cat_cardinalities': cat_cardinalities,\n",
    "            'n_classes': 2,\n",
    "            'backbone': {\n",
    "                'type': 'MLP',\n",
    "                'n_blocks': 3 if bins is None else 2,\n",
    "                'd_block': 512, # 256, 512, 1024\n",
    "                'dropout': 0.1, # 0, 0.05, 0.1, 0.2\n",
    "            },\n",
    "            'bins': bins,\n",
    "            'num_embeddings': (\n",
    "                None if bins is None else {\n",
    "                    'type': 'LinearEmbeddings', # 'PiecewiseLinearEmbeddings', 'LinearEmbeddings', 'LinearReLUEmbeddings', 'PeriodicEmbeddings'\n",
    "                    'd_embedding': 16, # 4, 8, 16, 32\n",
    "                    'activation': False, # True, False\n",
    "                    'version': 'B', # A, B\n",
    "                }\n",
    "            ),\n",
    "            'arch_type': 'tabm-mini', # 'tabm', 'tabm-mini', 'tabm-packed', 'tabm-normal', 'tabm-mini-normal'\n",
    "            'k': 32,\n",
    "            'share_training_batches': True,\n",
    "        }\n",
    "\n",
    "        trainer_config = {\n",
    "            'device': None,\n",
    "            'optimizer': 'AdamW',\n",
    "            'lr': 0.002, # 0.0005 ~ 0.01\n",
    "            'weight_decay': 3e-4, # 0.0001 ~ 0.005\n",
    "            'criterion': F.cross_entropy,\n",
    "            'patience': 3,\n",
    "        }\n",
    "\n",
    "        batch_size = 4096 # 2048, 4096\n",
    "        train_loader = to_dataloader(fold_train, batch_size=batch_size)\n",
    "        valid_loader = to_dataloader(fold_valid, batch_size=batch_size, is_shuffle=False)\n",
    "        test_loader = to_dataloader(fold_test, batch_size=batch_size, is_shuffle=False, is_train=False)\n",
    "\n",
    "        model = TabMWrapper(model_config, trainer_config)\n",
    "        history = model.fit(train_loader, valid_loader, verbose=False)\n",
    "        train_history.append(history)\n",
    "\n",
    "        valid_preds = model.predict(valid_loader)[:, 1]\n",
    "        fold_auc = roc_auc_score(fold_valid['임신 성공 여부'], valid_preds)\n",
    "\n",
    "        auc_scores.append(fold_auc)\n",
    "        test_pred = model.predict(test_loader)[:, 1]\n",
    "        fold_test_preds.append(test_pred)\n",
    "\n",
    "    valid_score = np.mean(auc_scores, axis=0)\n",
    "    print(f'[Data Seed {data_seed}] Valid AUC: {valid_score}')\n",
    "\n",
    "    test_score = calculate_auc(np.mean(fold_test_preds, axis=0), seed=data_seed)\n",
    "    print(f'[Data Seed {data_seed}] Test AUC: {test_score}')\n",
    "    print('-' * 60)\n",
    "    all_auc_test.append(test_score)\n",
    "\n",
    "print(f'AVG Test AUC{np.mean(all_auc_test)}')"
   ],
   "id": "e18ee9209a5acd26",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m data_seeds \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m7\u001B[39m]\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data_seed \u001B[38;5;129;01min\u001B[39;00m data_seeds:\n\u001B[1;32m---> 10\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(seed)\n\u001B[0;32m     12\u001B[0m     random\u001B[38;5;241m.\u001B[39mseed(seed)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\_compile.py:32\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     29\u001B[0m     disable_fn \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mdisable(fn, recursive)\n\u001B[0;32m     30\u001B[0m     fn\u001B[38;5;241m.\u001B[39m__dynamo_disable \u001B[38;5;241m=\u001B[39m disable_fn\n\u001B[1;32m---> 32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m disable_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:745\u001B[0m, in \u001B[0;36mDisableContext.__call__.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    741\u001B[0m prior_skip_guard_eval_unsafe \u001B[38;5;241m=\u001B[39m set_skip_guard_eval_unsafe(\n\u001B[0;32m    742\u001B[0m     _is_skip_guard_eval_unsafe_stance()\n\u001B[0;32m    743\u001B[0m )\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    746\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    747\u001B[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\random.py:46\u001B[0m, in \u001B[0;36mmanual_seed\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuda\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_is_in_bad_fork():\n\u001B[1;32m---> 46\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmps\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmps\u001B[38;5;241m.\u001B[39m_is_in_bad_fork():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\cuda\\random.py:127\u001B[0m, in \u001B[0;36mmanual_seed_all\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m    124\u001B[0m         default_generator \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdefault_generators[i]\n\u001B[0;32m    125\u001B[0m         default_generator\u001B[38;5;241m.\u001B[39mmanual_seed(seed)\n\u001B[1;32m--> 127\u001B[0m \u001B[43m_lazy_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed_all\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\cuda\\__init__.py:249\u001B[0m, in \u001B[0;36m_lazy_call\u001B[1;34m(callable, **kwargs)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_lazy_call\u001B[39m(\u001B[38;5;28mcallable\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[1;32m--> 249\u001B[0m         \u001B[38;5;28;43mcallable\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    251\u001B[0m         \u001B[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001B[39;00m\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001B[39;00m\n\u001B[0;32m    253\u001B[0m         \u001B[38;5;66;03m# else here if this ends up being important.\u001B[39;00m\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28;01mglobal\u001B[39;00m _lazy_seed_tracker\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\aimers_6th\\lib\\site-packages\\torch\\cuda\\random.py:125\u001B[0m, in \u001B[0;36mmanual_seed_all.<locals>.cb\u001B[1;34m()\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(device_count()):\n\u001B[0;32m    124\u001B[0m     default_generator \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdefault_generators[i]\n\u001B[1;32m--> 125\u001B[0m     \u001B[43mdefault_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-01T09:13:18.725967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 333\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 설정\n",
    "    d_block = trial.suggest_categorical(\"d_block\", [256, 512, 1024])\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.0, 0.05, 0.1, 0.2])\n",
    "\n",
    "    num_embeddings_type = trial.suggest_categorical(\n",
    "        \"num_embeddings_type\",\n",
    "        ['PiecewiseLinearEmbeddings']\n",
    "    )\n",
    "    d_embedding = trial.suggest_categorical(\"d_embedding\", [4, 8, 16, 32])\n",
    "    num_embeddings_activation = trial.suggest_categorical('activation', [True, False])\n",
    "    num_embeddings_version = trial.suggest_categorical('version', ['A', 'b'])\n",
    "\n",
    "    arch_type = trial.suggest_categorical(\n",
    "        \"arch_type\",\n",
    "        ['tabm', 'tabm-mini', 'tabm-packed', 'tabm-normal', 'tabm-mini-normal']\n",
    "    )\n",
    "\n",
    "    lr = trial.suggest_loguniform(\"lr\", 0.0005, 0.01)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 5e-3)\n",
    "\n",
    "\n",
    "    # d_block = trial.suggest_int(\"d_block\", 256, 1024, step=64)\n",
    "    # dropout = trial.suggest_uniform(\"dropout\", 0.0, 0.2)\n",
    "    #\n",
    "    # num_embeddings_type = trial.suggest_categorical(\n",
    "    #     \"num_embeddings_type\",\n",
    "    #     ['LinearEmbeddings', 'LinearReLUEmbeddings', 'PeriodicEmbeddings'] # 'PiecewiseLinearEmbeddings', 는 bins가 None이 아닐때에만 사용\n",
    "    # )\n",
    "    # d_embedding = trial.suggest_int(\"d_embedding\", 4, 64, step=8)\n",
    "    # num_embeddings_activation = trial.suggest_categorical('activation', [True, False])\n",
    "    # num_embeddings_version = trial.suggest_categorical('version', ['A', 'b'])\n",
    "    #\n",
    "    # arch_type = trial.suggest_categorical(\n",
    "    #     \"arch_type\",\n",
    "    #     ['tabm', 'tabm-mini', 'tabm-packed', 'tabm-normal', 'tabm-mini-normal']\n",
    "    # )\n",
    "    #\n",
    "    # lr = trial.suggest_loguniform(\"lr\", 0.0005, 0.01)\n",
    "    # weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-4, 5e-3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    all_auc_test = []\n",
    "    data_seeds = [1, 7]\n",
    "    for data_seed in data_seeds:\n",
    "        # seed 고정\n",
    "        torch.manual_seed(333)\n",
    "        np.random.seed(333)\n",
    "        random.seed(333)\n",
    "\n",
    "        train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "        test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "        train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "        test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "        fold_test_preds = []\n",
    "        auc_scores = []\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "        for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "            fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "            fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "            fold_train2 = fold_train.copy()\n",
    "            fold_test = test.copy()\n",
    "\n",
    "            # 전처리 (all_process 함수)\n",
    "            fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "            _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "            # 범주형, 수치형 컬럼 지정\n",
    "            cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "            numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "            # bins 및 feature 정보\n",
    "            bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "            # bins = None\n",
    "            n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "\n",
    "            # model_config 업데이트 (탐색한 하이퍼파라미터 반영)\n",
    "            model_config = {\n",
    "                'n_num_features': n_num_features,\n",
    "                'cat_cardinalities': cat_cardinalities,\n",
    "                'n_classes': 2,\n",
    "                'backbone': {\n",
    "                    'type': 'MLP',\n",
    "                    'n_blocks': 3 if bins is None else 2,\n",
    "                    'd_block': d_block,\n",
    "                    'dropout': dropout,\n",
    "                },\n",
    "                'bins': bins,\n",
    "                'num_embeddings': (\n",
    "                    None if bins is None else {\n",
    "                        'type': num_embeddings_type,\n",
    "                        'd_embedding': d_embedding,\n",
    "                        'activation': num_embeddings_activation,\n",
    "                        'version': num_embeddings_version,\n",
    "                    }\n",
    "                ),\n",
    "                'arch_type': arch_type,\n",
    "                'k': 32,\n",
    "                'share_training_batches': True,\n",
    "            }\n",
    "\n",
    "            # trainer_config 업데이트\n",
    "            trainer_config = {\n",
    "                'device': None,\n",
    "                'optimizer': 'AdamW',\n",
    "                'lr': lr,\n",
    "                'weight_decay': weight_decay,\n",
    "                'criterion': F.cross_entropy,\n",
    "                'patience': 3,\n",
    "            }\n",
    "\n",
    "            batch_size = 4096\n",
    "            train_loader = to_dataloader(fold_train, batch_size=batch_size)\n",
    "            valid_loader = to_dataloader(fold_valid, batch_size=batch_size, is_shuffle=False)\n",
    "            test_loader = to_dataloader(fold_test, batch_size=batch_size, is_shuffle=False, is_train=False)\n",
    "\n",
    "            # 모델 생성 및 학습\n",
    "            model = TabMWrapper(model_config, trainer_config)\n",
    "            history = model.fit(train_loader, valid_loader, verbose=False)\n",
    "\n",
    "            # 검증 데이터에 대한 예측 및 AUC 계산\n",
    "            valid_preds = model.predict(valid_loader)[:, 1]\n",
    "            fold_auc = roc_auc_score(fold_valid['임신 성공 여부'], valid_preds)\n",
    "            auc_scores.append(fold_auc)\n",
    "\n",
    "            # 테스트 데이터에 대한 예측 저장\n",
    "            test_pred = model.predict(test_loader)[:, 1]\n",
    "            fold_test_preds.append(test_pred)\n",
    "\n",
    "        valid_score = np.mean(auc_scores, axis=0)\n",
    "        print(f'[Data Seed {data_seed}] Valid AUC: {valid_score}')\n",
    "\n",
    "        # 두 데이터셋에 대해 fold별 테스트 예측 평균 후 AUC 계산\n",
    "        test_score = calculate_auc(np.mean(fold_test_preds, axis=0), seed=data_seed)\n",
    "        print(f'[Data Seed {data_seed}] Test AUC: {test_score}')\n",
    "        print('-' * 60)\n",
    "        all_auc_test.append(test_score)\n",
    "\n",
    "    avg_test_auc = np.mean(all_auc_test)\n",
    "    print(f'AVG Test AUC: {avg_test_auc}')\n",
    "\n",
    "    # 목적함수는 AVG Test AUC (최대화)\n",
    "    return avg_test_auc\n",
    "\n",
    "# Optuna 스터디 생성 (최대화 방향)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ],
   "id": "f96f275f8ee9e695",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 18:13:18,734] A new study created in memory with name: no-name-72ac1d93-e888-470b-9520-c032b70abd8c\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.949209Z",
     "start_time": "2025-03-30T02:15:51.934207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "old_auc = 0.744533 * 100\n",
    "old_std = 0.001171 * 100\n",
    "\n",
    "new_auc = total_auc_mean * 100\n",
    "new_std = total_auc_std * 100\n",
    "\n",
    "def calculate_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value) * 100 if old_value != 0 else float('inf')\n",
    "    return change, percentage_change\n",
    "\n",
    "def format_change(change):\n",
    "    return f\"{change:+.6f}\"\n",
    "\n",
    "# 각 지표의 변화량 계산\n",
    "auc_change, auc_pct = calculate_change(old_auc, new_auc)\n",
    "std_change, std_pct = calculate_change(old_std, new_std)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n========== 모델 성능 변화 ==========\")\n",
    "print(f\"{'Metric':<8}  {'AUC':>12}  {'Acc':>12}\")\n",
    "print(\"-\" * 36)\n",
    "print(f\"{'Old':<8}  {old_auc:>12.6f}  {old_std:>12.6f}\")\n",
    "print(f\"{'New':<8}  {new_auc:>12.6f}  {new_std:>12.6f}\")\n",
    "print(f\"{'Change':<8}  {format_change(auc_change):>12}  {format_change(std_change):>12}\")\n",
    "print(f\"{'% Change':<8}  {auc_pct:>11.4f}%  {std_pct:>11.4f}%\")\n",
    "print(\"=\" * 36)"
   ],
   "id": "8b4578cc3b830682",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 모델 성능 변화 ==========\n",
      "Metric             AUC           Acc\n",
      "------------------------------------\n",
      "Old          74.453300      0.117100\n",
      "New          73.845036      0.000000\n",
      "Change       -0.608264     -0.117100\n",
      "% Change      -0.8170%    -100.0000%\n",
      "====================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.996208Z",
     "start_time": "2025-03-30T02:15:51.986207Z"
    }
   },
   "source": [
    "tmp_submission = pd.DataFrame({f'tabm_{data_seed}': np.mean(test_preds, axis=0)})\n",
    "tmp_submission"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        tabm_10\n",
       "0      0.341478\n",
       "1      0.105108\n",
       "2      0.000232\n",
       "3      0.114351\n",
       "4      0.446093\n",
       "...         ...\n",
       "51266  0.231313\n",
       "51267  0.255745\n",
       "51268  0.141795\n",
       "51269  0.029850\n",
       "51270  0.151660\n",
       "\n",
       "[51271 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabm_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51266</th>\n",
       "      <td>0.231313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0.255745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51268</th>\n",
       "      <td>0.141795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>0.029850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>0.151660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51271 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.055439Z",
     "start_time": "2025-03-30T02:15:52.091208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "\n",
    "score = calculate_auc(tmp_submission, seed=data_seed)\n",
    "print(f'[seed {data_seed}]: {score}')"
   ],
   "id": "a64672a7154d813d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 10]: 0.74150757679765\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.117442Z",
     "start_time": "2025-03-30T02:15:53.103441Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "189382d5401e8bc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
