{
 "cells": [
  {
   "cell_type": "code",
   "id": "b0919eeb-bbb3-48d4-ae3f-3dac6b370d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:23.982476Z",
     "start_time": "2025-03-31T08:04:21.929868Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import rtdl_num_embeddings\n",
    "\n",
    "from Process_Function import RareCategoryTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "cd8b152b-c7a9-40f1-975a-516b764fcadd",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "id": "feed2e5f-fb44-4ec5-8546-711ee29221cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:25.789530Z",
     "start_time": "2025-03-31T08:04:24.967467Z"
    }
   },
   "source": [
    "data_seed = 10\n",
    "\n",
    "train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "# 학습/평가 데이터 로드\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "print(train.shape, test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205080, 68) (51271, 67)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:31.222979Z",
     "start_time": "2025-03-31T08:04:27.145369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from preprocess_DL import all_process\n",
    "\n",
    "train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "train, test = all_process(train, test)\n",
    "\n",
    "cat_cols = [col for col in train.columns if pd.api.types.is_categorical_dtype(train[col])]\n",
    "numeric_cols = [col for col in train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "print(f'수치형 변수: {len(numeric_cols)}개 \\n{numeric_cols}')\n",
    "print(f'범주형 변수: {len(cat_cols)}개 \\n{cat_cols}')\n",
    "print(train.shape, test.shape)"
   ],
   "id": "398c6a23d4086d96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수치형 변수: 57개 \n",
      "['임신 시도 또는 마지막 임신 경과 연수', '배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '시술_임신', '배아생성이유_기증용', '배아생성이유_난자 저장용', '배아생성이유_배아 저장용', '배아생성이유_현재 시술용']\n",
      "범주형 변수: 8개 \n",
      "['시술 시기 코드', '시술 당시 나이', '배란 유도 유형', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이', '시술유형_통합']\n",
      "(205080, 66) (51271, 65)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:32.265575Z",
     "start_time": "2025-03-31T08:04:32.159059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_feature_info(train, target_col='임신 성공 여부'):\n",
    "    n_num_features_ = len(numeric_cols)\n",
    "    cat_cardinalities_ = [train[col].nunique() for col in cat_cols]\n",
    "\n",
    "    return n_num_features_, cat_cardinalities_\n",
    "\n",
    "def to_dataloader(df, batch_size=256, is_shuffle=True, is_train=True, target_col='임신 성공 여부'):\n",
    "    X_num = torch.tensor(df[numeric_cols].values, dtype=torch.float32)\n",
    "    X_cat = torch.tensor(df[cat_cols].values, dtype=torch.long)\n",
    "\n",
    "    if is_train:\n",
    "        y = torch.tensor(df[target_col].values, dtype=torch.float32)\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat, y)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "    else:\n",
    "        tensor_dataset = TensorDataset(X_num, X_cat)\n",
    "        data_loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=is_shuffle)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "n_num_features, cat_cardinalities = get_feature_info(train)\n",
    "print(n_num_features)\n",
    "print(cat_cardinalities)\n",
    "\n",
    "train_loader = to_dataloader(train)\n",
    "test_loader = to_dataloader(test, is_shuffle=False, is_train=False)"
   ],
   "id": "7175bdaadb738a88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "[7, 7, 2, 3, 4, 5, 7, 9]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:33.557495Z",
     "start_time": "2025-03-31T08:04:33.543497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabMWrapper:\n",
    "    def __init__(self, model_config, trainer_config):\n",
    "        self.device = trainer_config.get(\"device\") or torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        )\n",
    "        self.lr = trainer_config.get(\"lr\", 0.001)\n",
    "        self.weight_decay = trainer_config.get(\"weight_decay\", 3e-4)\n",
    "        self.criterion = trainer_config.get(\"criterion\", F.cross_entropy)\n",
    "        self.patience = trainer_config.get(\"patience\", 3)\n",
    "\n",
    "        # 모델 생성\n",
    "        self.model = Model(**model_config).to(self.device)\n",
    "\n",
    "        optimizer_type = trainer_config.get(\"optimizer\", \"AdamW\")\n",
    "        params = make_parameter_groups(self.model)\n",
    "        if optimizer_type == \"AdamW\":\n",
    "            self.optimizer = torch.optim.AdamW(params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        elif optimizer_type == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(params, lr=self.lr)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer: {optimizer_type}\")\n",
    "\n",
    "    def fit(self, train_loader, valid_loader, num_epochs=30, verbose=True):\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_epoch = 0\n",
    "        best_auc = 0\n",
    "\n",
    "        best_model_state = None\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for x_num_batch, x_cat_batch, y_batch in train_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                # x_cat_batch가 없는 경우에도 대응 (None 체크)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                # 모델 출력: (batch, k, ?)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                # 앙상블 멤버의 예측값 평균 후, 마지막 차원 제거 (예: (B, 1) -> (B,))\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "            avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "            train_loss_history.append(avg_train_loss)\n",
    "\n",
    "            avg_val_loss = self.evaluate(valid_loader)\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping 체크 (validation loss 기준)\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_state = self.model.state_dict()\n",
    "                epochs_without_improvement = 0\n",
    "                best_epoch = epoch\n",
    "                # print(\"  New best validation loss! Model saved.\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                # print(f\"No improvement for {epochs_without_improvement} epoch(s).\")\n",
    "\n",
    "            if epochs_without_improvement >= self.patience:\n",
    "                break\n",
    "\n",
    "        # 학습 종료 후, best model의 가중치를 로드\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            print(f\"Best model weights loaded from epoch {best_epoch+1} with validation loss {best_val_loss:.4f}.\")\n",
    "\n",
    "        return {\"train_loss_history\": train_loss_history, \"val_loss_history\": val_loss_history}\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        # Validation 단계\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x_num_batch, x_cat_batch, y_batch in data_loader:\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device).long()\n",
    "\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                loss = self.criterion(ensemble_logits, y_batch)\n",
    "                val_loss += loss.item() * x_num_batch.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(data_loader.dataset)\n",
    "        return avg_val_loss\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                # 배치에 포함된 값의 개수를 확인하여 unpack\n",
    "                if len(batch) == 3:\n",
    "                    x_num_batch, x_cat_batch, _ = batch\n",
    "                elif len(batch) == 2:\n",
    "                    x_num_batch, x_cat_batch = batch\n",
    "                else:\n",
    "                    raise ValueError(\"Unexpected number of values in batch\")\n",
    "\n",
    "                x_num_batch = x_num_batch.to(self.device)\n",
    "                if x_cat_batch is not None:\n",
    "                    x_cat_batch = x_cat_batch.to(self.device)\n",
    "                outputs = self.model(x_num=x_num_batch, x_cat=x_cat_batch)\n",
    "                ensemble_logits = outputs.mean(dim=1).squeeze(-1)\n",
    "                probs = torch.softmax(ensemble_logits, dim=1)\n",
    "\n",
    "                preds_batch = probs.detach().cpu().numpy()\n",
    "                preds.extend(preds_batch.tolist())\n",
    "        return np.array(preds)\n"
   ],
   "id": "ff599c4b9c777fd3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:04:34.057049Z",
     "start_time": "2025-03-31T08:04:34.050050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model_config(n_num_features, cat_cardinalities, bins, arch_type):\n",
    "    model_config = {\n",
    "        'n_num_features': n_num_features,\n",
    "        'cat_cardinalities': cat_cardinalities,\n",
    "        'n_classes': 2,\n",
    "        'backbone': {\n",
    "            'type': 'MLP',\n",
    "            'n_blocks': 3 if bins is None else 2,\n",
    "            'd_block': 512, # 256, 512, 1024\n",
    "            'dropout': 0.1,\n",
    "        },\n",
    "        'bins': bins,\n",
    "        'num_embeddings': (\n",
    "            None if bins is None else {\n",
    "                'type': 'PiecewiseLinearEmbeddings',\n",
    "                'd_embedding': 16,\n",
    "                'activation': False,\n",
    "                'version': 'B',\n",
    "            }\n",
    "        ),\n",
    "        'arch_type': arch_type,\n",
    "        'k': 32,\n",
    "        'share_training_batches': True,\n",
    "    }\n",
    "    return model_config\n"
   ],
   "id": "32f926927cf34e34",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T08:26:07.810285Z",
     "start_time": "2025-03-31T08:17:18.649804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 333\n",
    "all_auc = []\n",
    "test_preds = []\n",
    "train_history = []\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "data_seeds = [7, 1]\n",
    "for data_seed in data_seeds:\n",
    "    train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "    test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "\n",
    "    train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "    test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "\n",
    "    fold_test_preds = []\n",
    "    auc_scores = []\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "        fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "        fold_train2 = fold_train.copy()\n",
    "        fold_test = test.copy()\n",
    "\n",
    "        fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "        _, fold_test = all_process(fold_train2, fold_test)\n",
    "\n",
    "        cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "        numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "\n",
    "        # TabM\n",
    "        # arch_type = 'tabm'\n",
    "        # bins = None\n",
    "\n",
    "        # TabM-mini with the piecewise-linear embeddings.\n",
    "        arch_type = 'tabm-mini'\n",
    "        bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "        n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "        model_config = get_model_config(n_num_features, cat_cardinalities, bins, arch_type)\n",
    "\n",
    "        trainer_config = {\n",
    "            'device': None,\n",
    "            'optimizer': 'AdamW',\n",
    "            'lr': 2e-3,\n",
    "            'weight_decay': 3e-4,\n",
    "            'criterion': F.cross_entropy,\n",
    "            # 'criterion': F.binary_cross_entropy_with_logits,\n",
    "            'patience': 3,\n",
    "        }\n",
    "\n",
    "        batch_size = 4096\n",
    "        train_loader = to_dataloader(fold_train, batch_size=batch_size)\n",
    "        valid_loader = to_dataloader(fold_valid, batch_size=batch_size, is_shuffle=False)\n",
    "        test_loader = to_dataloader(fold_test, batch_size=batch_size, is_shuffle=False, is_train=False)\n",
    "\n",
    "        model = TabMWrapper(model_config, trainer_config)\n",
    "        history = model.fit(train_loader, valid_loader, verbose=False)\n",
    "        train_history.append(history)\n",
    "\n",
    "        valid_preds = model.predict(valid_loader)[:, 1]\n",
    "        fold_auc = roc_auc_score(fold_valid['임신 성공 여부'], valid_preds)\n",
    "        print(f'Fold {fold + 1} AUC: {fold_auc}')\n",
    "\n",
    "        auc_scores.append(fold_auc)\n",
    "        test_pred = model.predict(test_loader)[:, 1]\n",
    "        fold_test_preds.append(test_pred)\n",
    "\n",
    "    # test_preds.append(fold_test_preds) # 나중에 sample 데이터 사용할때 사용\n",
    "\n",
    "    valid_score = np.mean(auc_scores, axis=0)\n",
    "    print(f'[Data Seed {data_seed}] Valid AUC: {valid_score}')\n",
    "\n",
    "    from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "    # mean_test_preds_for_this_seed = np.mean(fold_test_preds, axis=0)\n",
    "    test_score = calculate_auc(np.mean(fold_test_preds, axis=0), seed=data_seed)\n",
    "    print(f'[Data Seed {data_seed}] Test AUC: {test_score}')\n",
    "\n",
    "\n",
    "# 전체 결과에 대한 평균 및 표준편차 출력\n",
    "total_auc_mean = np.mean(auc_scores)\n",
    "total_auc_std = np.std(auc_scores)\n",
    "print('-' * 60)\n",
    "print(f'Total Average AUC: {total_auc_mean:.6f} (STD: {total_auc_std:.6f})')"
   ],
   "id": "e18ee9209a5acd26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights loaded from epoch 5 with validation loss 0.4896.\n",
      "Fold 1 AUC: 0.7379780856482877\n",
      "Best model weights loaded from epoch 7 with validation loss 0.4867.\n",
      "Fold 2 AUC: 0.7394981986181133\n",
      "Best model weights loaded from epoch 6 with validation loss 0.4899.\n",
      "Fold 3 AUC: 0.7365417950753128\n",
      "Best model weights loaded from epoch 9 with validation loss 0.4893.\n",
      "Fold 4 AUC: 0.7367039139176061\n",
      "Best model weights loaded from epoch 8 with validation loss 0.4869.\n",
      "Fold 5 AUC: 0.7409627223276896\n",
      "[Data Seed 7] Valid AUC: 0.738336943117402\n",
      "[Data Seed 7] Test AUC: 0.7423944131894281\n",
      "Best model weights loaded from epoch 7 with validation loss 0.4875.\n",
      "Fold 1 AUC: 0.7407844660719476\n",
      "Best model weights loaded from epoch 6 with validation loss 0.4892.\n",
      "Fold 2 AUC: 0.737130458282671\n",
      "Best model weights loaded from epoch 8 with validation loss 0.4887.\n",
      "Fold 3 AUC: 0.7394164346686344\n",
      "Best model weights loaded from epoch 7 with validation loss 0.4886.\n",
      "Fold 4 AUC: 0.7375383807414659\n",
      "Best model weights loaded from epoch 7 with validation loss 0.4881.\n",
      "Fold 5 AUC: 0.7389297311402154\n",
      "[Data Seed 1] Valid AUC: 0.738759894180987\n",
      "[Data Seed 1] Test AUC: 0.7397580086449876\n",
      "------------------------------------------------------------\n",
      "Total Average AUC: 0.738760 (STD: 0.001320)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T07:31:27.420874Z",
     "start_time": "2025-03-31T07:31:11.505406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seed = 333\n",
    "# torch.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "#\n",
    "# # data_seed 값 목록\n",
    "# data_seeds = [1, 7]\n",
    "#\n",
    "# # 각 data_seed별 AUC를 저장할 딕셔너리\n",
    "# auc_data = {}\n",
    "#\n",
    "# # model_config와 trainer_config는 첫 번째 data_seed에서 저장 (모든 실험에서 동일한 구성이면 이를 사용)\n",
    "# model_config_saved = None\n",
    "# trainer_config_saved = None\n",
    "#\n",
    "# # data_seed 별 실험 수행\n",
    "# for data_seed in data_seeds:\n",
    "#     print(f\"\\n*** Data seed: {data_seed} ***\")\n",
    "#     train_path = f'../data/custom_train_{data_seed}.csv'\n",
    "#     test_path = f'../data/custom_test_{data_seed}.csv'\n",
    "#\n",
    "#     train = pd.read_csv(train_path).drop(columns=['ID'])\n",
    "#     test = pd.read_csv(test_path).drop(columns=['ID'])\n",
    "#\n",
    "#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#     auc_scores = []\n",
    "#     fold_test_preds = []\n",
    "#\n",
    "#     for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train['임신 성공 여부'])):\n",
    "#         # 데이터 분할 및 복사\n",
    "#         fold_train = train.iloc[train_idx].copy().reset_index(drop=True)\n",
    "#         fold_valid = train.iloc[valid_idx].copy().reset_index(drop=True)\n",
    "#         fold_train2 = fold_train.copy()  # 후처리에 사용할 별도 복사본\n",
    "#         fold_test = test.copy()\n",
    "#\n",
    "#         # 데이터 전처리 (all_process 함수 사용)\n",
    "#         fold_train, fold_valid = all_process(fold_train, fold_valid)\n",
    "#         fold_train2, fold_test = all_process(fold_train2, fold_test)\n",
    "#\n",
    "#         # 카테고리형, 수치형 변수 구분\n",
    "#         cat_cols = [col for col in fold_train.columns if pd.api.types.is_categorical_dtype(fold_train[col])]\n",
    "#         numeric_cols = [col for col in fold_train.columns if col not in cat_cols and col != '임신 성공 여부']\n",
    "#\n",
    "#         # TabM-mini 모델 설정 (piecewise-linear embeddings 사용)\n",
    "#         arch_type = 'tabm-mini'\n",
    "#         bins = rtdl_num_embeddings.compute_bins(torch.tensor(fold_train[numeric_cols].values))\n",
    "#         n_num_features, cat_cardinalities = get_feature_info(fold_train)\n",
    "#         model_config = get_model_config(n_num_features, cat_cardinalities, bins, arch_type)\n",
    "#\n",
    "#         # trainer 설정\n",
    "#         trainer_config = {\n",
    "#             'device': None,\n",
    "#             'optimizer': 'AdamW',\n",
    "#             'lr': 2e-3,\n",
    "#             'weight_decay': 3e-4,\n",
    "#             'criterion': F.cross_entropy,\n",
    "#             'patience': 3,\n",
    "#         }\n",
    "#\n",
    "#         # 데이터 로더 생성\n",
    "#         batch_size = 4096\n",
    "#         train_loader = to_dataloader(fold_train, batch_size=batch_size)\n",
    "#         valid_loader = to_dataloader(fold_valid, batch_size=batch_size, is_shuffle=False)\n",
    "#         test_loader = to_dataloader(fold_test, batch_size=batch_size, is_shuffle=False, is_train=False)\n",
    "#\n",
    "#         # 모델 생성 및 학습\n",
    "#         model = TabMWrapper(model_config, trainer_config)\n",
    "#         history = model.fit(train_loader, valid_loader, verbose=False)\n",
    "#\n",
    "#         # 검증 데이터 예측 및 AUC 계산\n",
    "#         valid_preds = model.predict(valid_loader)[:, 1]\n",
    "#         fold_auc = roc_auc_score(fold_valid['임신 성공 여부'], valid_preds)\n",
    "#         print(f'Data seed {data_seed}, Fold {fold + 1} AUC: {fold_auc:.5f}')\n",
    "#         auc_scores.append(fold_auc)\n",
    "#\n",
    "#         # 테스트 예측 (추후 ensemble 등 활용 가능)\n",
    "#         test_pred = model.predict(test_loader)[:, 1]\n",
    "#         fold_test_preds.append(test_pred)\n",
    "#\n",
    "#     from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "#     score = calculate_auc(np.mean(fold_test_preds, axis=0), seed=data_seed)\n",
    "#\n",
    "#     # 현재 data_seed의 평균 AUC 계산\n",
    "#     seed_auc_mean = np.mean(auc_scores)\n",
    "#     auc_data[data_seed] = seed_auc_mean\n",
    "#     print(f\"Data seed {data_seed} - Average AUC: {seed_auc_mean:.5f}\\n\")\n",
    "#\n",
    "#\n",
    "# # 최종 평균 AUC (전체 data_seed의 평균)\n",
    "# avg_auc = np.mean(list(auc_data.values()))\n",
    "#\n",
    "# # 결과 DataFrame 구성: model_config, trainer_config와 각 data_seed의 평균 AUC, 그리고 전체 평균\n",
    "# final_results = pd.DataFrame({\n",
    "#     'model_config': [model_config_saved],\n",
    "#     'trainer_config': [trainer_config_saved],\n",
    "#     'data1': [auc_data.get(1)],\n",
    "#     'data7': [auc_data.get(7)],\n",
    "#     'avg': [avg_auc]\n",
    "# })\n",
    "#\n",
    "# # 결과를 CSV 파일로 저장\n",
    "# final_results.to_csv('final_results.csv', index=False)\n",
    "# print(\"최종 결과가 'final_results.csv' 파일로 저장되었습니다.\")"
   ],
   "id": "f96f275f8ee9e695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Data seed: 1 ***\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 68\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;66;03m# 모델 생성 및 학습\u001B[39;00m\n\u001B[0;32m     67\u001B[0m model \u001B[38;5;241m=\u001B[39m TabMWrapper(model_config, trainer_config)\n\u001B[1;32m---> 68\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# 검증 데이터 예측 및 AUC 계산\u001B[39;00m\n\u001B[0;32m     71\u001B[0m valid_preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(valid_loader)[:, \u001B[38;5;241m1\u001B[39m]\n",
      "Cell \u001B[1;32mIn[5], line 53\u001B[0m, in \u001B[0;36mTabMWrapper.fit\u001B[1;34m(self, train_loader, valid_loader, num_epochs, verbose)\u001B[0m\n\u001B[0;32m     50\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 53\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m x_num_batch\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     55\u001B[0m avg_train_loss \u001B[38;5;241m=\u001B[39m epoch_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader\u001B[38;5;241m.\u001B[39mdataset)\n\u001B[0;32m     56\u001B[0m train_loss_history\u001B[38;5;241m.\u001B[39mappend(avg_train_loss)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.949209Z",
     "start_time": "2025-03-30T02:15:51.934207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "old_auc = 0.744533 * 100\n",
    "old_std = 0.001171 * 100\n",
    "\n",
    "new_auc = total_auc_mean * 100\n",
    "new_std = total_auc_std * 100\n",
    "\n",
    "def calculate_change(old_value, new_value):\n",
    "    change = new_value - old_value\n",
    "    percentage_change = (change / old_value) * 100 if old_value != 0 else float('inf')\n",
    "    return change, percentage_change\n",
    "\n",
    "def format_change(change):\n",
    "    return f\"{change:+.6f}\"\n",
    "\n",
    "# 각 지표의 변화량 계산\n",
    "auc_change, auc_pct = calculate_change(old_auc, new_auc)\n",
    "std_change, std_pct = calculate_change(old_std, new_std)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n========== 모델 성능 변화 ==========\")\n",
    "print(f\"{'Metric':<8}  {'AUC':>12}  {'Acc':>12}\")\n",
    "print(\"-\" * 36)\n",
    "print(f\"{'Old':<8}  {old_auc:>12.6f}  {old_std:>12.6f}\")\n",
    "print(f\"{'New':<8}  {new_auc:>12.6f}  {new_std:>12.6f}\")\n",
    "print(f\"{'Change':<8}  {format_change(auc_change):>12}  {format_change(std_change):>12}\")\n",
    "print(f\"{'% Change':<8}  {auc_pct:>11.4f}%  {std_pct:>11.4f}%\")\n",
    "print(\"=\" * 36)"
   ],
   "id": "8b4578cc3b830682",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== 모델 성능 변화 ==========\n",
      "Metric             AUC           Acc\n",
      "------------------------------------\n",
      "Old          74.453300      0.117100\n",
      "New          73.845036      0.000000\n",
      "Change       -0.608264     -0.117100\n",
      "% Change      -0.8170%    -100.0000%\n",
      "====================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "aa2b7f75-b22e-465f-a646-ce56d96303a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:51.996208Z",
     "start_time": "2025-03-30T02:15:51.986207Z"
    }
   },
   "source": [
    "tmp_submission = pd.DataFrame({f'tabm_{data_seed}': np.mean(test_preds, axis=0)})\n",
    "tmp_submission"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        tabm_10\n",
       "0      0.341478\n",
       "1      0.105108\n",
       "2      0.000232\n",
       "3      0.114351\n",
       "4      0.446093\n",
       "...         ...\n",
       "51266  0.231313\n",
       "51267  0.255745\n",
       "51268  0.141795\n",
       "51269  0.029850\n",
       "51270  0.151660\n",
       "\n",
       "[51271 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tabm_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51266</th>\n",
       "      <td>0.231313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51267</th>\n",
       "      <td>0.255745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51268</th>\n",
       "      <td>0.141795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51269</th>\n",
       "      <td>0.029850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51270</th>\n",
       "      <td>0.151660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51271 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.055439Z",
     "start_time": "2025-03-30T02:15:52.091208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from LG_Aimers_6th.cal_auc import calculate_auc\n",
    "\n",
    "score = calculate_auc(tmp_submission, seed=data_seed)\n",
    "print(f'[seed {data_seed}]: {score}')"
   ],
   "id": "a64672a7154d813d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seed 10]: 0.74150757679765\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T02:15:53.117442Z",
     "start_time": "2025-03-30T02:15:53.103441Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "189382d5401e8bc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
